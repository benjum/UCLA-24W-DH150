{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4edc1037-9b05-44c6-8c07-219f69328b77",
      "metadata": {},
      "source": "# Topic modeling\n\nWe are going to look at data from the [20 Newsgroups](http://qwone.com/~jason/20Newsgroups/) dataset.  These are postings to newsgroups in 20 different categories.\n\nScikit-learn has a function for downloading the data.  See: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n\n## LDA\n\nLatent Dirichlet Allocation:  a topic model that generates topics based on a set of documents' word frequencies.\n\n* Get a \"dictionary\" that has IDs for all the words along with a record of their word frequencies.\n* Use our \"bag of words\" to generate a list for each document containing its words and their frequencies\n* Use gensim to generate an LDA model\n\n## Gensim\n\n* \"Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.\"\n* [gensim website](https://radimrehurek.com/gensim/)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011b5d42-d37e-4e71-ab13-d99e91048d41",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.datasets import fetch_20newsgroups"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b361ee-d241-4bf7-b3ef-0a32dcc2e62a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad16c2c1-2207-4233-8281-307161fadbed",
      "metadata": {
        "scrolled": false,
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "print(data.DESCR)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73716a29-da6e-41cb-8436-ed5672d03e06",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "x = data.data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae459b3-e221-441d-81c1-02ea865a25ed",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "len(x)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0267475a-529a-48cc-a91d-b3fde92af8aa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc714e58-530e-4693-be86-97f4ff144588",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data.target_names"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa66e72-9d94-43dd-977a-c73fedab972d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data.target"
    },
    {
      "cell_type": "markdown",
      "id": "7924c31b-452b-437a-a765-08e932ccec12",
      "metadata": {},
      "source": "We use NLTK to pre-process the words."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bae2b9-1a9b-4a0d-9b72-2ba9c42c8580",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\n# getting corpora\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512c234a-f674-40a7-8311-e21aa308148b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "myStopWords = list(punctuation) + stopwords.words('english')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac2b161-d260-4655-a5eb-d4907f18e09c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab39c868-8420-4873-9991-1765a22aab75",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "[w for w in word_tokenize(x[0].lower()) if w not in myStopWords]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a948b9-75b6-424e-94b3-6c16700b2287",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "docs = []\nfor i in x:\n    docs.append([w for w in word_tokenize(i.lower()) if w not in myStopWords])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d53c1a8-cb62-4119-94bb-178619912b52",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "docs[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5b80233-5cc9-43f1-a2ed-d69815f39d98",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from nltk.stem.porter import PorterStemmer\n#from nltk.stem import LancasterStemmer"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2e3130-fb17-4e22-b775-bf6e98f878fd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Create p_stemmer of class PorterStemmer\np_stemmer = PorterStemmer()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e877102-13db-43ed-82d1-551ec474d977",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "docs_stemmed = []\nfor i in docs:\n    docs_stemmed.append([p_stemmer.stem(w) for w in i])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5436a74-4f45-4e7d-96ca-12e7ef806c45",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "docs_stemmed[0]"
    },
    {
      "cell_type": "markdown",
      "id": "8092a60b-32b1-4173-aa67-794881638608",
      "metadata": {},
      "source": "Here we use gensim to make the dictionary and corpus structures, and to employ the LDA model to extract groups (aka topics) and the distribution of words for each topic."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2294d9-ab78-42e0-83ca-321bc381503d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from gensim import corpora, models\nimport gensim"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da8cbe2-dc2f-495a-b8b5-983e296d9b1f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "dictionary = corpora.Dictionary(docs_stemmed)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde8095b-24a9-49c7-8f10-a224696616e9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "len(dictionary)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c28ea8a-5962-49e1-aa9d-2f14900865ee",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "dictionary.filter_extremes(no_below=10, no_above=0.5)\n# could also trim with keep_n=1000 or similar to keep only the top words"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0932895-df99-4a9b-be70-039fdc2a50ae",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "len(dictionary)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d17faa4-eca1-4647-a0f7-66163435e2b4",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "print(dictionary.token2id)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679a4c55-b149-47c6-ac03-8d007b2e7e37",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(dictionary.token2id['patient'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b986523-2eb2-4555-935a-5de37eb9f84a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "dictionary[1668]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa8266d-bb5d-4626-95a1-91d2df9dd084",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "corpus = [dictionary.doc2bow(text) for text in docs_stemmed]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5383fd9b-0267-4d5c-ab54-eb06e8c082bc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(corpus[30])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac1baa1f-ba7d-4242-bec7-0d95fb484e8e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "dictionary[276]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de5415e-1ef5-477c-b7a2-5ce47d6e4e36",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "docs_stemmed[30]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284854d0-92a4-482e-937e-904e93e21be7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "wordid = corpus[30][0]\nprint(dictionary[wordid[0]],wordid[1])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba5282e3-5ec2-47d0-b5b6-2875af2e5360",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "for i in corpus[30]:\n    print(dictionary[i[0]], i[1])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f364d19a-d545-485b-bb5b-25be3cfba874",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ldamodel = gensim.models.ldamodel.LdaModel(corpus, \n                                           num_topics=20, \n                                           id2word = dictionary, \n                                           passes=5)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01662301-327f-421a-9908-83ab0c969cee",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ldamodel.show_topics(num_topics=20)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34abdd71-d58e-447b-a5c1-94e91090ed73",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "for i in ldamodel.print_topics(num_topics=20, num_words=20):\n    print(i[0])\n    print(i[1])\n    print('\\n')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d701e5-1f5f-484e-bdd1-7bb2e5ab634a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data.target_names"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f68fcae-e88b-4759-bf47-393a9577f037",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport re"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e75458a-89a5-4535-83b0-bcfcdf8472b5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "re.split(re.escape(' + ') + '|' + re.escape('*'), 'hi + me*4')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190467bd-c55d-43e2-96f1-4026e4a346e0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "fig,ax = plt.subplots(5,4,figsize=(15,20))\nax = ax.flatten()\nfor i in ldamodel.print_topics(num_topics=20, num_words=20):\n    x = []\n    y = []\n    count = 0\n    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n        if count % 2 == 0:\n            y.insert(0,float(j))\n        else:\n            x.insert(0,j)\n        count += 1\n    ax[i[0]].barh(x,y,height=0.5)\nplt.tight_layout()"
    },
    {
      "cell_type": "markdown",
      "id": "7b67a169-d4ed-438d-ac19-d3f7302beb73",
      "metadata": {},
      "source": "# TF-IDF (Term Frequency Inverse Document Frequency)\n\nTF-IDF is similar to bag-of-words, but it down weights words appearing frequently across lots of documents."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3416752c-d9ac-455b-b982-ddc7cce0923a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "#Initialize the model\ntfidf = gensim.models.TfidfModel(corpus)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d709d9-a14c-408e-b2e1-67d82583e45b",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "corpus[30]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc23d80-e01c-40cd-964c-2aa077283263",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "# apply transformation\ntfidf[corpus[30]]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a6056c0-7920-47fc-a533-9bc99e2eb4d2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "corpus_transformed = tfidf[corpus]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4e8ef0-9314-4eae-9827-e155bbdcb4c0",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "source": "corpus_transformed[30]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5c1c47",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "tfidf.num_docs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287fdb77-fab9-46b2-8e21-d0a315adff8b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ldamodel_tfidf = gensim.models.ldamodel.LdaModel(corpus_transformed, \n                                           num_topics=20, \n                                           id2word = dictionary, \n                                           passes=20)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e572e6e-13cb-4e07-a360-ede842fd5d9c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "for i in ldamodel_tfidf.print_topics(num_topics=20, num_words=20):\n    print(i[0])\n    print(i[1])\n    print('\\n')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649a45f0-4dec-4241-a167-24ac08a912fb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "fig,ax = plt.subplots(5,4,figsize=(15,20))\nax = ax.flatten()\nfor i in ldamodel_tfidf.print_topics(num_topics=20, num_words=20):\n    x = []\n    y = []\n    count = 0\n    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n        if count % 2 == 0:\n            y.insert(0,float(j))\n        else:\n            x.insert(0,j)\n        count += 1\n    ax[i[0]].barh(x,y,height=0.5)\nplt.tight_layout()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}