{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1dfcbb0",
      "metadata": {},
      "source": "# Searching for meaning in our ML\n\nUnderstanding the particular code details of this notebook is secondary!  Your first goal should be to understand that there are techniques and tools for understanding your model."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5660469",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.inspection import PartialDependenceDisplay\nfrom sklearn.inspection import DecisionBoundaryDisplay"
    },
    {
      "cell_type": "markdown",
      "id": "49dfcc4e",
      "metadata": {},
      "source": "We'll use an artificial dataset of three clusters using Scikit-Learn's `make_blobs`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750afc29",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X, y = make_blobs(n_samples=300, centers=3, random_state=42)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a0d0014",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c9e933",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ycolors = ['red','green','blue']"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "418eadd5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.scatter(X[:,0],\n         X[:,1],\n         c=[ycolors[i] for i in y])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b718ee3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d70fa1a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Fit Logistic Regression model\nlr_model = LogisticRegression(max_iter=1000)\nlr_model.fit(X_train, y_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8fe48e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Look at the feature coefficients\nprint('intercepts:\\n',lr_model.intercept_)\nprint('coefficients:\\n',lr_model.coef_)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d6b86b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Look at the boundaries of predictions in feature space\nDecisionBoundaryDisplay.from_estimator(lr_model, \n                                       X,\n                                       response_method=\"predict\",\n                                       cmap=\"RdBu\", \n                                       alpha=0.5\n)\n\nplt.scatter(X[:,0], X[:,1], c=y);"
    },
    {
      "cell_type": "markdown",
      "id": "df5bb2b8",
      "metadata": {},
      "source": "The model equation gives us direct access to these boundaries:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c4f3ec",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def mkgrid(a=0):\n\n    plt.scatter(X[:,0], X[:,1], c=y);\n\n    # Create a grid of points\n    xbnd = np.linspace(-11, 8, 100)\n    ybnd = np.linspace(-11, 13, 100)\n    Xbnd, Ybnd = np.meshgrid(xbnd, ybnd)\n\n    # calculate softmax values across the grid\n    # and assign them into Z for visualization\n    Z = np.zeros((100,100))\n    for i in range(100):\n        for j in range(100):\n            denominator = 0\n            for k in range(3):\n              denominator += np.exp((lr_model.intercept_[k] +\n                                     xbnd[i] * lr_model.coef_[k,0] +\n                                     ybnd[j] * lr_model.coef_[k,1]))\n            probs = np.exp((lr_model.intercept_[a] +\n                            xbnd[i] * lr_model.coef_[a,0] +\n                            ybnd[j] * lr_model.coef_[a,1])) / denominator\n            Z[i,j] = probs\n\n    # Plot the grid points\n    plt.pcolormesh(Xbnd, Ybnd, Z.T, alpha=0.4, cmap='seismic', vmin=0.0, vmax=1.0)\n    plt.colorbar()\n    plt.show()\n\nipywidgets.interact(mkgrid, a=(0,2));"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8de5e5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Print classification report\ny_pred = lr_model.predict(X_test)\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b20f1a4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Look at the confusion matrix\nprint(confusion_matrix(y_test, y_pred))"
    },
    {
      "cell_type": "markdown",
      "id": "9484e1e9",
      "metadata": {},
      "source": "## Partial Dependence Plots\nThese plots show the marginal effect of varying a given feature while keeping all other features constant."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdcf96a0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features_to_plot = [0, 1, (0, 1)]\nPartialDependenceDisplay.from_estimator(lr_model, \n                                        X_train, \n                                        features_to_plot,\n                                        target=2,\n                                        grid_resolution=50);"
    },
    {
      "cell_type": "markdown",
      "id": "3c379c6e",
      "metadata": {},
      "source": "## LIME\nLocal Interpretable Model-agnostic Explanations.  LIME takes an instance and generates perturbed samples around it, fits a local interpretable model (like a linear model), and quantifies the contribution of features in this local neighborhood."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54d535a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "!pip install lime"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5792a3c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from lime import lime_tabular"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1870c5ee",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# LIME explanation for a single instance\nexplainer = lime_tabular.LimeTabularExplainer(X_train)\n\n# Choose a random instance for explanation\nrandom_instance_index = np.random.randint(0, len(X_test))\ninstance_to_explain = X_test[random_instance_index]\nprint('Instance coordinates:',instance_to_explain)\n\n# Explain the prediction using LIME\nexplanation = explainer.explain_instance(instance_to_explain, \n                                         lr_model.predict_proba,\n                                         top_labels=3)\n\n# Display the explanation\nexplanation.show_in_notebook()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510452e1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def limepoint():\n    \n    # LIME explanation for a single instance\n    explainer = lime_tabular.LimeTabularExplainer(X_train)\n\n    # Choose a random instance for explanation\n    random_instance_index = np.random.randint(0, len(X_test))\n    instance_to_explain = X_test[random_instance_index]\n    print('Instance coordinates:',instance_to_explain)\n\n    # Explain the prediction using LIME\n    explanation = explainer.explain_instance(instance_to_explain, \n                                             lr_model.predict_proba,\n                                             top_labels=3)\n\n    # Display the explanation\n    explanation.show_in_notebook()\n\n    DecisionBoundaryDisplay.from_estimator(lr_model, \n                                           X,\n                                           response_method=\"predict\",\n                                           cmap=\"RdBu\", \n                                           alpha=0.5\n    )\n    plt.scatter(X[:,0],\n                X[:,1],\n                c=[ycolors[i] for i in y])\n    plt.scatter(instance_to_explain[0],\n                instance_to_explain[1],\n                c='black',s=70)\n    "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7663e4f8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "limepoint()"
    },
    {
      "cell_type": "markdown",
      "id": "e60f5cbd",
      "metadata": {},
      "source": "## SHAP\nSHapley Additive exPlanations is a \"game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\" -- see https://github.com/shap/shap and [linked papers](https://github.com/shap/shap?tab=readme-ov-file#citations)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4326c6c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "!pip install shap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d51e14",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import shap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7eeccb7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "explainer = shap.LinearExplainer(lr_model, X_train)\nshap_values = explainer.shap_values(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f068a3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "shap.summary_plot(shap_values, X_test)"
    },
    {
      "cell_type": "markdown",
      "id": "a36b8db4",
      "metadata": {},
      "source": "# Applying this back to handwritten digits"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d3b830",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport sklearn.datasets\nimport sklearn.model_selection\nimport sklearn.metrics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d460630",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "d = sklearn.datasets.load_digits()\n\nx = d.data\ny = d.target\n\nx_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(\n        x, y, test_size=0.2, random_state=42, stratify=y)\n\nscaler = sklearn.preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b97b5c4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import sklearn.linear_model\nlr_classifier = sklearn.linear_model.LogisticRegression()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca0c44eb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "lr_classifier.fit(x_scaled, y_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84fe0d6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = lr_classifier.predict(x_test_scaled)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4200503d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(f\"Accuracy: {sklearn.metrics.accuracy_score(y_test, y_pred):.2%}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93076e8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\ncm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d94686e",
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "outputs": [],
      "source": "# LIME explanation for a single instance\nexplainer = lime_tabular.LimeTabularExplainer(x_scaled)\n\n# Choose a random instance for explanation\nrandom_instance_index = np.random.randint(0, len(x_test_scaled))\ninstance_to_explain = x_test_scaled[random_instance_index]\nplt.imshow(instance_to_explain.reshape(8,8),cmap='binary')\n\n# Explain the prediction using LIME\nexplanation = explainer.explain_instance(instance_to_explain, \n                                         lr_classifier.predict_proba,\n                                         top_labels=3)\n\n# Display the explanation\nexplanation.show_in_notebook()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bb5ae0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "explainer = shap.LinearExplainer(lr_classifier, x_scaled)\nshap_values = explainer.shap_values(x_test_scaled)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cbf22f7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "shap.summary_plot(shap_values, x_test_scaled)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0355a4b3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def whichfeature(feature_num = 43):\n    checkimage = np.zeros(64)\n    checkimage[feature_num] = 1\n    plt.imshow(checkimage.reshape(8,8), cmap='binary')\n    \nipywidgets.interact(whichfeature, feature_num=(0,63));"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8dabd2c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features_to_plot = [43, 21, (43, 21)]\nPartialDependenceDisplay.from_estimator(lr_classifier, \n                                        x_scaled, \n                                        features_to_plot,\n                                        target=2,\n                                        grid_resolution=50);"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}