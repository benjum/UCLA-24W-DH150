{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "478440d2",
      "metadata": {},
      "source": "# Bagging:  Bootstrap Aggregation "
    },
    {
      "cell_type": "markdown",
      "id": "4d7504e7-a8ff-4a80-83e3-c7559f0fa64a",
      "metadata": {},
      "source": "## Bagging (explicitly)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d8ede5-2db2-4160-9800-d97f80baf65a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.linear_model\nimport sklearn.tree\nimport sklearn.metrics\nimport sklearn.model_selection"
    },
    {
      "cell_type": "markdown",
      "id": "b63f626c-9751-4c77-823c-bce606c3b724",
      "metadata": {},
      "source": "## First: create a dataset to explore\n\nWe will start by looking at a very simple set of data with a very simple linear relationship.\n\nBagging will not give a better result than simple linear regression.  However, this will serve as an easy-to-understand example and we will apply bagging in more appropriate contexts afterwards."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3579b647-3b0e-4b4d-bd13-f741618a1a41",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x = np.linspace(0,10,100)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b448c683-b034-4a57-aa7f-093be3b7c499",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "np.random.seed(42)\nnoise = np.random.normal(0,1.5,100)\n\ny = x + noise"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6a0e0c-f0af-496a-b4c0-873c50670fea",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x,y,'ko')"
    },
    {
      "cell_type": "markdown",
      "id": "3b493fdf-aa04-435c-ac3b-1f45678171fe",
      "metadata": {},
      "source": "## Straight-forward linear regression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c43857d-fd93-47f0-9e06-753600b38886",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x.reshape(-1,1), y, random_state=42)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7712ebca-bc79-4d30-9b2a-014783a5866d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "lin_reg = sklearn.linear_model.LinearRegression()\nlin_reg.fit(x_train,y_train)\nprint('R2 score: ',lin_reg.score(x_test, y_test))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7c6818-4a5f-4e3c-9430-792dfc45172b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nplt.plot([0,10],lin_reg.predict([[0],[10]]))"
    },
    {
      "cell_type": "markdown",
      "id": "ee77ce05-dc10-46f7-83bb-4a395063551f",
      "metadata": {},
      "source": "## Bootstrap samples and aggregation\n\nUse bootstrapping to get training samples, then take average of the regressor's predictions for any given sample."
    },
    {
      "cell_type": "markdown",
      "id": "74934aa0-d569-4ec5-a75b-f4eeda14f7d7",
      "metadata": {},
      "source": "We will select `k` samples with replacement, train our linear regression algorithm, and then repeat the process `t` times."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a33d7cb-86b8-4290-afb6-1049ea963ca9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "k = 5\nt = 5"
    },
    {
      "cell_type": "markdown",
      "id": "3ea73414-155f-45ac-a386-54c50c91f404",
      "metadata": {},
      "source": "Since we need to select an element from `x_train` and `y_train` in tandem, we make choices among the list of indices."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74253e8c-7442-495b-aa1c-b35535f0e5fe",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ix = range(0,len(x_train))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f6738f9-c241-4475-8d7b-0febfa7bf567",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "np.random.choice(ix, k)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5363bc7d-86e2-4c8c-a99b-97d292a1593b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "newix = np.random.choice(ix, k)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906aefad-768b-4cd6-a72e-38097d84b4f2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train[newix], y_train[newix]"
    },
    {
      "cell_type": "markdown",
      "id": "0c81af0d-9af9-45ea-8e6e-9220040fef27",
      "metadata": {},
      "source": "Here's where we repeat the training `t` times on samples with `k` elements chosen from `(x_train, y_train)`"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4022adc7-7238-4562-9c39-b589135de00e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "lin_regs = []\nfor i in range(t):\n    \n    newix = np.random.choice(ix, k)\n    \n    lin_regs.append(sklearn.linear_model.LinearRegression())\n    \n    lin_regs[i].fit(x_train[newix], y_train[newix])"
    },
    {
      "cell_type": "markdown",
      "id": "ad604d37-9ed2-46fe-8585-7af8b8fcb2cb",
      "metadata": {},
      "source": "We plot all of the linear fits:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c61ee85-cc91-4fbc-a255-78738924ae24",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x,y,'ko')\nx_edge = [[0],[10]]\nfor i in range(t):\n    plt.plot(x_edge, lin_regs[i].predict(x_edge))"
    },
    {
      "cell_type": "markdown",
      "id": "ef065a45-12f8-4902-9564-9ce528915fc8",
      "metadata": {},
      "source": "When looking at predictions, we take an average over all the predictors."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a40483-f08a-4b38-9552-2ebb1500d977",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x,y,'ko')\n\nxnew = np.linspace(0,10,100)\nynew = []\nfor i in xnew:\n    tmpx = [[i]]\n    n = [j.predict(tmpx) for j in lin_regs]\n    ynew.append(np.mean(n))\n\nplt.plot(xnew,ynew,'b')\nplt.plot([0,10],lin_reg.predict([[0],[10]]), 'g')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75072e0-8e3f-45bd-9dd5-134dc496e32e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = []\nfor i in x_test:\n    n = [j.predict([i]) for j in lin_regs]\n    y_pred.append(np.mean(n))\nr2score = sklearn.metrics.r2_score(y_test, y_pred)\nprint('R2 score: ',r2score)"
    },
    {
      "cell_type": "markdown",
      "id": "09c80777-9bee-4026-bfcd-82d04bb2afd3",
      "metadata": {},
      "source": "The above is very good, considering we only trained 5 times with 5 samples each time.\n\nRepeat the above for other numbers."
    },
    {
      "cell_type": "markdown",
      "id": "b4d14769-c06d-4a14-940c-d845336efdee",
      "metadata": {},
      "source": "# Decision Trees"
    },
    {
      "cell_type": "markdown",
      "id": "98050127-8b44-47f8-a039-cca1d9d07906",
      "metadata": {},
      "source": "We are going to repeat this process now using Decision Trees instead of Linear Regression."
    },
    {
      "cell_type": "markdown",
      "id": "71872fa4-b594-4301-a48a-534b4e5150e6",
      "metadata": {},
      "source": "First, we train one decision tree to see how it does."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d07cc25-6f80-4eff-b714-6f4e3edc21b3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "tree_reg = sklearn.tree.DecisionTreeRegressor()\ntree_reg.fit(x_train,y_train)\nprint('R2 score: ',tree_reg.score(x_test, y_test))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c356416-6a66-4c88-ba2c-d167e8065b56",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nxnew = np.linspace(0,10,1000).reshape(-1,1)\nynew = tree_reg.predict(xnew)\nplt.plot(xnew,ynew)"
    },
    {
      "cell_type": "markdown",
      "id": "bd0ce247-bd59-41ee-b77f-77caac448744",
      "metadata": {},
      "source": "The decision tree here very much overfits to the training data.\n\nWe will see whether this can be improved by using bootstrapping."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8afc08b9-ebc8-4b44-952e-fd1e40f96792",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "k = 5\nt = 5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9bec1e-7f75-42a3-9860-b63ded29faca",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "tree_regs = []\nfor i in range(t):\n    \n    newix = np.random.choice(ix, k)\n    \n    tree_regs.append(sklearn.tree.DecisionTreeRegressor())\n    \n    tree_regs[i].fit(x_train[newix], y_train[newix])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d4bb24-83bc-4748-9642-0b27863e7113",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nx_edge = np.linspace(0,10,1000).reshape(-1,1)\nfor i in range(t):\n    plt.plot(x_edge,tree_regs[i].predict(x_edge))"
    },
    {
      "cell_type": "markdown",
      "id": "ea8a3feb-dcd4-4921-b8a7-61ac46804f57",
      "metadata": {},
      "source": "The above shows the various decision trees trained on only `k` points.\n\nFor our aggregate prediction, we average the predictions over all of the `t` predictors."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55801507-84da-4a5c-bada-1c71f19a4c30",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\n\nxnew = np.linspace(0,10,1000).reshape(-1,1)\nynew = []\nfor i in xnew:\n    n = [j.predict([i]) for j in tree_regs]\n    ynew.append(np.mean(n))\n\nplt.plot(xnew,ynew)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e185db7-ba4a-413c-a17b-cb4b77f9061f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = []\nfor i in x_test:\n    n = [j.predict([i]) for j in tree_regs]\n    y_pred.append(np.mean(n))\nr2score = sklearn.metrics.r2_score(y_test, y_pred)\nprint(r2score)"
    },
    {
      "cell_type": "markdown",
      "id": "cde3fa06-5448-484e-a73f-dbf730610a0b",
      "metadata": {},
      "source": "This model outperforms the single decision tree!"
    },
    {
      "cell_type": "markdown",
      "id": "36caca90",
      "metadata": {},
      "source": "## Bagging (with Scikit-Learn)"
    },
    {
      "cell_type": "markdown",
      "id": "68bad5e4",
      "metadata": {},
      "source": "## BaggingRegressor with Linear Regression"
    },
    {
      "cell_type": "markdown",
      "id": "66f5529f",
      "metadata": {},
      "source": "Scikit-Learn's BaggingRegressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c62435",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.ensemble import BaggingRegressor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138530cd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Be careful, by the way, about using Regressor vs Classifier (below we'll also use Classifiers)\n\nbag_reg = BaggingRegressor(sklearn.linear_model.LinearRegression(), \n                           n_estimators=5,\n                           max_samples=5, \n                           bootstrap=True, \n                           n_jobs=-1)\n\nbag_reg.fit(x_train, y_train)\n\ny_pred = bag_reg.predict(x_test)\nprint(bag_reg.__class__.__name__, sklearn.metrics.r2_score(y_test, y_pred))\n\nplt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nplt.plot([0,10],bag_reg.predict([[0],[10]]), 'g')\nplt.plot([0,10],lin_reg.predict([[0],[10]]), 'r')"
    },
    {
      "cell_type": "markdown",
      "id": "63c54017",
      "metadata": {},
      "source": "Try tinkering around with the number of estimators and the number of samples.\n\nNote: max_samples is the integer number of samples if you specify an integer, but it is the fraction of the total number of data points if you specify a float."
    },
    {
      "cell_type": "markdown",
      "id": "ddbac44e",
      "metadata": {},
      "source": "## Random Forest"
    },
    {
      "cell_type": "markdown",
      "id": "9b351be5",
      "metadata": {},
      "source": "Scikit-Learn's RandomForestRegressor: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n\n* once you start becoming familiar with the ideas behind the algorithm, try exploring the documentation detailing the input parameters"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fc038c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "rf_reg = sklearn.ensemble.RandomForestRegressor(n_jobs=-1,\n                                                random_state=42)\nrf_reg.fit(x_train,y_train)\nprint('R2 score: ',rf_reg.score(x_test, y_test))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2f3d56",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nxnew=np.linspace(0,10,1000).reshape(-1,1)\nynew=rf_reg.predict(xnew)\nplt.plot(xnew,ynew)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419621c8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "rf_reg = sklearn.ensemble.RandomForestRegressor(max_depth=3,\n                                                n_jobs=-1,\n                                                random_state=42)\nrf_reg.fit(x_train,y_train)\nprint('R2 score: ',rf_reg.score(x_test, y_test))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa693aa1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x_train,y_train,'ko')\nplt.plot(x_test,y_test,'bo')\nxnew=np.linspace(0,10,1000).reshape(-1,1)\nynew=rf_reg.predict(xnew)\nplt.plot(xnew,ynew)"
    },
    {
      "cell_type": "markdown",
      "id": "cbb38b01",
      "metadata": {},
      "source": "A random forest is a collection of trees -> we can use our tree visualization methods to look at them."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3b59b6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "len(rf_reg.estimators_)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b4f4596",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import ipywidgets\n\ndef outtree(n):\n    text_representation = sklearn.tree.export_text(rf_reg.estimators_[n])\n    print(text_representation)\n    \nipywidgets.interactive(outtree,n=range(len(rf_reg.estimators_)))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b4c6f1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def outtree(n):\n    plt.figure(figsize=(12,8))\n    sklearn.tree.plot_tree(rf_reg.estimators_[n], \n                   feature_names=['x'],\n                   filled=True);\n\nipywidgets.interactive(outtree,n=range(len(rf_reg.estimators_)))"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}