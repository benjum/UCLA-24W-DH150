{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1d5c75b1-6b15-49c2-869b-6af409ef317e",
      "metadata": {},
      "source": "# An Introduction to Regression and Classification with Scikit-Learn"
    },
    {
      "cell_type": "markdown",
      "id": "5c87bb76-8931-4c36-90ec-2c5c852da999",
      "metadata": {},
      "source": "## The data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352cd2d4-32c1-4ae8-8c6f-35a489becbe1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
    },
    {
      "cell_type": "markdown",
      "id": "a2a73018-67a9-4e0d-8e3d-4352d7b47c9f",
      "metadata": {},
      "source": "Side note:\n* I will be posting data files and shared notebooks in a GitHub repository: https://github.com/benjum/UCLA-24W-DH150\n* If you're a bit rusty on the Python, do not worry.  I will be distributing Python-relevant tutorial materials later this week.\n    * If you later review the tutorial materials and the following still makes no sense, you may want to consult with me about how challenging this course will be for you."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6dc56b2-1e6e-428e-a19f-514a29452f1b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data = pd.read_csv('https://raw.githubusercontent.com/benjum/UCLA-24W-DH150/main/Data/gdp-vs-lifesatisfaction.csv')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d949bd-170a-47ce-84cc-aebc4add7a5b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data = data.to_numpy()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6718eaf-69aa-4535-a1f1-81ebb07eb299",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f1e248-cd18-491f-a85d-d1c45c7283f2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Assign the appropriate elements to x and y\nx = data[:,1]\ny = data[:,2]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45077345-5159-4b07-8634-f685b0e0af8f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Make a scatter plot\n\nplt.plot(x,y,'ko')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "70f3c05c-fe13-4355-ba97-5811e7ad4745",
      "metadata": {},
      "source": "## Scikit-learn\n\n* Scikit-Learn docs: https://scikit-learn.org/stable/index.html\n* Linear Regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n* K-Nearest Neighbors Regressor: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n* K-Nearest Neighbors Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n* Logistic Regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
    },
    {
      "cell_type": "markdown",
      "id": "bb5f4519-27c1-41ee-952a-c76d39f43877",
      "metadata": {},
      "source": "## Linear Regression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bce4549-f67a-41d2-a7b8-6f2b92df0da7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# sklearn is our library and \n# linear_model is a package within the library that contains various linear models to use\n\nimport sklearn.linear_model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34fb5ae2-a4b4-4592-a193-7a2451380113",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# To use a machine learning algorithm in scikit-learn\n# we use the relevant \"Estimator\" object\n# Here that estimator object is \"LinearRegression\"\n\nmodel = sklearn.linear_model.LinearRegression()"
    },
    {
      "cell_type": "markdown",
      "id": "3ce843f0-d172-4ffd-a121-89605a2114ee",
      "metadata": {},
      "source": "Technical note: sklearn usually wants to work with feature arrays x that are 2D arrays of shape (n_samples, n_features).  Therefore, if your x is a 1D numpy array, you'll need to reshape it to be like (n_samples, 1).  You can achieve this with `x.reshape(-1,1)`, with the `-1` meaning that the n_samples value will be inferred from `x`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b4c429-cd84-487a-acc7-ba0e8a74af29",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Reshape x (https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)\n# The \"-1\" means that the length is inferred.\n# Here the first dimension is the number of elements\n\nx = x.reshape(-1,1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25a7c8a-3f1e-4f1b-a04e-0306edb04dc3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\nmodel.fit(x,y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b433eb-6452-4f82-8212-b102833edfb0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Make a prediction\nx_test = [[25000]]\nmodel.predict(x_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f72b6bdb-889c-4634-bca7-af666c77865f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x,y,'ko')\n\nx_new = np.linspace(8000,58000,2)\nx_new = x_new.reshape(-1,1)\ny_pred = model.predict(x_new)\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0450075c-f5b2-4e69-9139-e4b56a43d8b0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# For this model, we can retrieve parameters for our model equation\nprint(model.coef_, model.intercept_)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b927ac-f58e-47ad-af5a-d003b0286ee7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x,y,'ko')\n\nx_new = np.linspace(8000,58000,2)\nx_new = x_new.reshape(-1,1)\n\n# the predicted y values are now from a model equation, \n# not from results of calling the predict function\ny_pred = model.intercept_ + model.coef_ * x_new\n\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc05035-a5ea-4b3f-9387-76fc9cc2079f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# If we had test data, we could also try to ascertain an error\n# Here we'll calculate an error simply on the same set of data\n# that is, we'll compare the actual y values with the model's predicted y values\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint('MSE = ', mean_squared_error(y, model.predict(x)))\nprint('R^2 = ', r2_score(y, model.predict(x)))"
    },
    {
      "cell_type": "markdown",
      "id": "47161a5e-9cae-4afb-b29c-ec1aa4587129",
      "metadata": {},
      "source": "## K-Nearest Neighbors"
    },
    {
      "cell_type": "markdown",
      "id": "bdccaa6d-7488-4444-ad5f-a93b1ac62910",
      "metadata": {},
      "source": "Replacing the Linear Regression model with the K-Nearest Neighbors model in the previous code is as simple as replacing these two lines:\n\n```python\nimport sklearn.linear_model\nmodel = sklearn.linear_model.LinearRegression()\n```\n\nwith these two:\n\n```python\nimport sklearn.neighbors\nmodel = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)\n```\n\nDo note, however, that changing the model like this changes what is getting trained and what is being \"learned\":\n* K-Nearest Neighbors does not learn the optimum number of neighbors, that is a hyperparameter\n* K-Nearest Neighbors does not learn the optimal value for any model coefficients"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4e8c70-1dd9-4bee-b066-9f5e223b965a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import sklearn.neighbors"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96e33cbe-ddb6-4f1a-bdfa-0471a01c26b5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Our estimator object is now KNeighborsRegressor\n# and we initialize one of its parameters, \n# namely the number of nearest neighbors to use in the algorithm\n\nmodel = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)"
    },
    {
      "cell_type": "markdown",
      "id": "04c93fa1-3a23-40f3-ac06-f8264cb4ec7f",
      "metadata": {},
      "source": "Technical note: sklearn usually wants to work with feature arrays x that are 2D arrays of shape (n_samples, n_features).  Therefore, if your x is a 1D numpy array, you'll need to reshape it to be like (n_samples, 1).  You can achieve this with `x.reshape(-1,1)`, with the `-1` meaning that the n_samples value will be inferred from `x`."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a2fdee-4dd4-4529-ab0e-bffcb7462e0a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Reshape x (https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.reshape.html)\n# The \"-1\" means that the length is inferred.\n# Here the first dimension is the number of elements\n\nx = x.reshape(-1,1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3099c5f-befc-489d-82fe-1a36a6d80cb2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\nmodel.fit(x,y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924fe9a5-cf93-4683-aa44-6af2fd4889c0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Make a prediction\nx_test = [[25000]]\nmodel.predict(x_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5484f392-e344-4f59-a5ee-1775e421536d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x,y,'ko')\n\n# NOTE!! We include a lot of points in our x array here for plotting the predictions\n# Linear regression was ok with only 2 points because a line is determined by 2 points\n# Here there can be very sharp jumps in value along the range in x\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\ny_pred = model.predict(x_new)\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "659a8e6f-511f-4331-aada-b7f097fffb92",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# If we had test data, we could also try to ascertain an error\n# Here we'll calculate an error simply on the same set of data\n# that is, we'll compare the actual y values with the model's predicted y values\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nprint('MSE = ', mean_squared_error(y, model.predict(x)))\nprint('R^2 = ', r2_score(y, model.predict(x)))"
    },
    {
      "cell_type": "markdown",
      "id": "7003cc97-3200-4f3d-a64b-61c1207eec35",
      "metadata": {},
      "source": "### Visualizing the algorithm's output as a function of n_neighbors\n\nI will ocassionally use the Python library `ipywidgets` to make interactive visualizations.  These can provide useful insights into the scaling of functions with respect to input parameters.\n* https://ipywidgets.readthedocs.io/en/stable/\n\nHere we'll use it to make an interactive visualization that allows us to see how the prediction curve of KNN varies a function of n_neighbors for this data set."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bc897c-bf6b-4297-b0e8-6b74b1e13ba8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import ipywidgets"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d508d6-1092-4a33-9eee-01f1269c54ed",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def knn(n=3):\n\n    model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=n)\n    model.fit(x,y)\n    \n    plt.plot(x,y,'ko')\n\n    x_new = np.linspace(8000,58000,100000)\n    x_new = x_new.reshape(-1,1)\n    y_pred = model.predict(x_new)\n    plt.plot(x_new, y_pred)\n\n    plt.show()\n    \nipywidgets.interact(knn,n=(1,29))"
    },
    {
      "cell_type": "markdown",
      "id": "d31d43b7-51d4-4e0d-8a54-ad089a6fb38d",
      "metadata": {},
      "source": "# Classification"
    },
    {
      "cell_type": "markdown",
      "id": "e582c205-05cb-4ea0-a8dc-b121a9c71013",
      "metadata": {},
      "source": "Classification is simple to do here as well.  However, it is not just a matter of switching the algorithm.  Classification is applied for different types of data, and it has different applicable algorithms as well as different performance metrics."
    },
    {
      "cell_type": "markdown",
      "id": "1b24ee89-759b-4378-adaf-eafbe82f5a35",
      "metadata": {},
      "source": "We are going to use the same data, but now convert it into 0 and 1 values.  Classification is appropriate for a discrete set of values like this."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eda42c2-1004-4609-b5c1-c52646b29fd3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7122ec-a5b9-4e99-b344-06281dae38bf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y >= 6.5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e168f18-a40f-4d45-b684-aa76813cffa0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y = (y >= 6.5)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16b2dec-22f3-48a1-83ca-c5bcb6054b8b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import sklearn.neighbors"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e879e8-68be-4a5f-85ba-5b73047cb5e9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Before for regression:\n# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=1)\n\n# Classifier\nmodel = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558e17ae-bc55-4eb7-a5d0-0b0bf64c24b7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\nmodel.fit(x,y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed8028c-ac18-425e-96bd-597125ba5b05",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Make a prediction\nx_test = [[25000]]\nmodel.predict(x_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60f6cf3-02f7-4f19-b582-e4aff0befdfd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x, y, 'ko')\n\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\ny_pred = model.predict(x_new)\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "78e4422e-d9a1-4678-bbf2-817d3b35c157",
      "metadata": {},
      "source": "## Classification's performance metrics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6460cd8-3f12-46e3-80ed-05738db05567",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model.score(x, y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bab31c6-40b4-421a-b567-0b96fb2a45bb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# If the model correctly classifies i points and misclassifies j points out of k total\n# the score should be i/k\n28/29"
    },
    {
      "cell_type": "markdown",
      "id": "3c4ef6f4-bef6-4cca-8ca9-f7cf134536ad",
      "metadata": {},
      "source": "The above is termed the accuracy.  By default, each algorithm's \"score\" method may be a little different:\n* [`score` for KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8960befb-8cdf-48f9-9f27-5d1773314586",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Note that when calculating the precision and recall here, if your classes are not 0/1\n# you will need to specify what class is positive vs negative (the \"pos_label\")\n\nprint(f\"Accuracy: {sklearn.metrics.accuracy_score(y, model.predict(x)):.2%}\")\nprint(f\"Precision: {sklearn.metrics.precision_score(y, model.predict(x), pos_label=1):.2%}\")\nprint(f\"Recall: {sklearn.metrics.recall_score(y, model.predict(x), pos_label=1):.2%}\")"
    },
    {
      "cell_type": "markdown",
      "id": "02151ba7-b88e-49bf-8b27-2c0be15358a5",
      "metadata": {},
      "source": "You can get more information on the model performance with a confusion matrix. \n\nIn the case of binary classification, the confusion matrix shows true negatives, true positives, false positives, and false positives."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be59a97-5450-4809-99ab-8aa7e5574e81",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import confusion_matrix"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976e35ed-ecc4-43a3-a4cd-fbdb3be6c2fa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "confusion_matrix(y, model.predict(x))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9212b748-ac35-4060-9d0f-a00b32af76fa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "confmat = confusion_matrix(y, model.predict(x))\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(confmat)\n\n# the below just sets the axis labels, tick marks, and text inside the boxes\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, confmat[i,j], ha='center', va='center', color='red')\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "173bdb01-c659-44ee-9fb1-5fdce89f3832",
      "metadata": {},
      "source": "And with the classification report, we can see the precision and recall (and other scores) broken down according to class."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03097f6b-f62c-4aa8-ad3f-c40db807798e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import classification_report"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a8cd1a-93ff-462e-a909-0c915fbfe43a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(classification_report(y, model.predict(x)))"
    },
    {
      "cell_type": "markdown",
      "id": "159e2f25-9075-4f5c-b47f-3c50f1688c69",
      "metadata": {},
      "source": "We discussed precision and recall for binary classification, but for multi-class classification problems, these metrics can be computed in slightly different ways depending on how one does averaging. \n\nA macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), a weighted average will compute the metric independently for each class but then additionally take into account the support when calculating the overall average, and a micro-average will aggregate the contributions of all classes to compute the average metric. \n\nIn a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes)."
    },
    {
      "cell_type": "markdown",
      "id": "d0fbaf61-181f-49d4-99e9-f0b41c050b0b",
      "metadata": {},
      "source": "# Classification based on Logistic Regression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27fc7bbe",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import sklearn.linear_model"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9a90f2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Before with linear regression\n# model = sklearn.linear_model.LinearRegression()\n\n# Classifier with logistic regression\nmodel = sklearn.linear_model.LogisticRegression()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e154c994-5e86-4600-946e-de00601da141",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Train the model\nmodel.fit(x,y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72e43f1e-ade6-473e-9d7d-8fee7a438dda",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x, y, 'ko')\n\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\ny_pred = model.predict(x_new)\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "fbb33733-f709-44ae-9c2b-c4518c559274",
      "metadata": {},
      "source": "Note what is different about the above prediction curve relative to that for KNN Classification.  Can you make them more similar?"
    },
    {
      "cell_type": "markdown",
      "id": "25cf752c-0663-44a7-8c1a-21edf976909d",
      "metadata": {},
      "source": "## Learned model"
    },
    {
      "cell_type": "markdown",
      "id": "c0d47ea9-4d38-4014-a55c-109fbb8e5409",
      "metadata": {},
      "source": "With logistic regression, the optimal values for coefficients of a specific model equation have been learned."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec40fbe-6ca9-4b8b-a5ac-8014de202c8a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# For this model, we can actually retrieve parameters for our model equation\nprint(model.coef_, model.intercept_)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece97b61-84c1-4a46-91af-5e1ebeb9d1d3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model.classes_"
    },
    {
      "cell_type": "markdown",
      "id": "dbc078ce-c249-4731-8de0-f6e15d55d4ce",
      "metadata": {},
      "source": "What's the `intercept_` and `coef_` for a logistic model?\n\n$$f(x) = \\frac{1}{1+e^{-(a_0 + a_1 x)}}$$"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c7418b-29a1-4c0b-9203-b3b87117c629",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x,y,'ko')\n\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\n\n# the predicted y values are now from a model equation, \n# not from results of calling the predict function\ny_model = 1 / (1 + np.exp(-(model.intercept_ + model.coef_ * x_new)))\n\nplt.plot(x_new, y_model)\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "b2148168-e619-46ca-a818-65fcc76c6a56",
      "metadata": {},
      "source": "The learned model $f(x)$ gives us a probability of belonging to the \"positive\" class, and we can take $f(x) > 0.5$, for example, to be a threshold for classifying as one class vs another. "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed10a689-039e-45bb-86ff-d9edd8b7a6ca",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize what the predictions are for this model\n\nplt.plot(x,y,'ko')\n\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\n\n# the predicted y values are now from a model equation, \n# not from results of calling the predict function\ny_model = 1 / (1 + np.exp(-(model.intercept_ + model.coef_ * x_new)))\n\nplt.plot(x_new, y_model)\n\nplt.axhline(0.5,color='r',linestyle='--')\n\nx_new = np.linspace(8000,58000,100000)\nx_new = x_new.reshape(-1,1)\ny_pred = model.predict(x_new)\nplt.plot(x_new, y_pred)\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "03593703-dc2f-40e6-8014-95dbbfdab485",
      "metadata": {},
      "source": "## Classification's performance metrics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460ae0be-5e6d-4d4b-8172-dcbe53ded867",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model.score(x, y)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dbd3d60-8557-48e0-8482-f284d27d51de",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# If the model correctly classifies i points and misclassifies j points out of k total\n# the score should be i/k\n27/29"
    },
    {
      "cell_type": "markdown",
      "id": "525205b0-305c-4be4-bcf6-97a5764eb468",
      "metadata": {},
      "source": "The above is termed the accuracy.  By default, each algorithm's \"score\" method may be a little different:\n* [`score` for KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81c7c86-637e-4811-8d88-eff5d469ae51",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Note that when calculating the precision and recall here, if your classes are not 0/1\n# you will need to specify what class is positive vs negative (the \"pos_label\")\n\nprint(f\"Accuracy: {sklearn.metrics.accuracy_score(y, model.predict(x)):.2%}\")\nprint(f\"Precision: {sklearn.metrics.precision_score(y, model.predict(x), pos_label=1):.2%}\")\nprint(f\"Recall: {sklearn.metrics.recall_score(y, model.predict(x), pos_label=1):.2%}\")"
    },
    {
      "cell_type": "markdown",
      "id": "9e6e2e08-28b1-42ab-8671-525332cc021d",
      "metadata": {},
      "source": "You can get more information on the model performance with a confusion matrix. \n\nIn the case of binary classification, the confusion matrix shows true negatives, true positives, false positives, and false positives."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0b534b-5a46-4aad-97fe-f18b57b43675",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import confusion_matrix"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0555d2a4-5898-48e9-be08-22344215f87f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "confusion_matrix(y, model.predict(x))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2769c841-9893-4763-b361-5f3f3a889aa2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "confmat = confusion_matrix(y, model.predict(x))\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(confmat)\n\n# the below just sets the axis labels, tick marks, and text inside the boxes\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, confmat[i,j], ha='center', va='center', color='red')\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "id": "ce9b98f4-52fc-4a01-b384-5fb59d0daf03",
      "metadata": {},
      "source": "And with the classification report, we can see the precision and recall (and other scores) broken down according to class."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7e6dff-0ea7-4b22-9979-8d31cf64721b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import classification_report"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c090a5-569a-440a-912a-a3ec21001e46",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(classification_report(y, model.predict(x)))"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}