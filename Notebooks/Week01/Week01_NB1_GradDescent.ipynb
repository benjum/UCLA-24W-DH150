{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Gradient Descent\n\n[There is no need to follow this code.  Simply execute the cells down to (but just before) \"Supplemental\"]\n\nGradient descent is an iterative optimization algorithm for determining the local minimum of a differentiable function.\n\nFor a function _f_, the gradient of _f_ with respect to the independent variables gives the direction in which _f_ increases the fastest.  By taking steps opposite to the gradient, one can iteratively move towards lower and lower values until one reaches the minimum of _f_ (ideally)."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "<img src=\"https://www.ahmednasr.at/wp-content/uploads/2017/05/gradientDescent.jpg\" alt='gradient descent' width='500'/>"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "For an _f(x)_ that depends on only one variable:\n* choose a starting point, $x_0$\n* take a step towards a new $x$:\n  * $x_{n+1} = x_{n} - \\eta*df/dx$\n  * here, $\\eta$ is a user-chosen step size and $df/dx$ is the 1D gradient of f (i.e., the derivative)\n* continue until the value of _f(x)_ stops changing within some low tolerance"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Execute the first four cells:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Import our modules\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interactive, interact, interactive_output\nfrom ipywidgets import fixed, VBox, HBox, jslink, Play, FloatSlider, IntSlider\nimport matplotlib.pyplot as plt"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "We're going to look at a very simple example function:\n\n$$f(x) = e^{-x}\\sin(5x)$$\n\nWe'll use gradient descent to try to iteratively find a minimum (i.e. a location where $df/dx=0$).  To do that, we'll need the derivative:\n\n$$\\frac{df}{dx} = -e^{-x}\\sin(5x) + 5e^{-x}\\cos(5x)$$\n\nWe'll also need:\n* an initial value for x\n* the coefficient $\\eta$ that determines how much to vary x during a given iteration"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def f(x):\n    return np.exp(-x) * np.sin(5 * x)\ndef df(x):\n    return -np.exp(-x) * np.sin(5 * x) + 5 * np.cos(5 *x) * np.exp(-x)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def gradient_descent_2(x0, eta=.1, tol=1e-6, num_iters=10):\n    xtheory = np.linspace(0.5, 3, 300)\n    ytheory = f(xtheory)\n    x = [x0]\n    i = 0\n\n    fig = plt.figure(figsize=(5,3))\n    curve = plt.plot(xtheory, ytheory, 'b-')\n    plt.plot(x[-1],f(x[-1]),'ko',markersize=5)\n    while i < num_iters:\n        x_prev = x[-1]\n        grad = df(x_prev)\n        x_curr = x_prev - eta * grad\n        x.append(x_curr)\n        if f(x_curr) > 10:\n            break\n        plt.plot(x_curr,f(x_curr),'ko',markersize=5)\n        plt.plot([x_prev,x_curr],[f(x_prev),f(x_curr)],'k--')\n        \n        if np.abs(x_curr - x_prev) < tol:\n            break\n        i += 1\n    \n    fig.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "a = FloatSlider(value=1.3,min=0.5,max=3,description='x0')\nb = IntSlider(value=0,min=0,max=50,description='num_iters')\nc = FloatSlider(value=0.2,min=0.01,max=1.0,step=0.01,description='eta')\ncontrols = VBox([a,b,c])\nplotwidget = interactive_output(gradient_descent_2, {\n                       'x0':a,\n                       'num_iters':b,\n                       'eta':c,\n                       'tol':fixed(1e-6)});\ndef achanged(change):\n    b.value = 0\na.observe(achanged,'value')\n\ndef cchanged(change):\n    b.value = 0\nc.observe(cchanged,'value')\n\nplay = Play(value=0,min=0,max=1000,step=1,interval=1000,description=\"Press play\",disabled=False)\njslink((play, 'value'), (b, 'value'))\ngradmov = VBox([controls,plotwidget,play])\n\ndisplay(gradmov)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Supplemental\n\n**The following is provided if you want to see some code steps that build up to the interactive graphic**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x = np.linspace(0.5, 5.5, 500)\ny = f(x)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(x,y);"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "fig = plt.figure(figsize=(12,7))\ncurve = plt.plot(x, y, 'b-')\npoints = plt.plot(x[100],y[100],'ko',markersize=10)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def gradient_descent(x0, eta=.1, tol=1e-6, num_iters=10):\n    xtheory = np.linspace(0.5, 5.5, 500)\n    ytheory = f(xtheory)\n    x = [x0]\n    i = 0\n\n    fig = plt.figure(figsize=(12,7))\n    curve = plt.plot(xtheory, ytheory, 'b-')\n    plt.plot(x[-1],f(x[-1]),'ko',markersize=10)\n    while i < num_iters:\n        x_prev = x[-1]\n        grad = df(x_prev)\n        x_curr = x_prev - eta * grad\n        x.append(x_curr)\n        if f(x_curr) > 10:\n            break\n        plt.plot(x_curr,f(x_curr),'ko',markersize=10)\n        \n        if np.abs(x_curr - x_prev) < tol:\n            break\n        i += 1\n    \n    fig.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "gradient_descent(1.5, eta=.3, tol=1e-6, num_iters=10)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "interactive(gradient_descent,x0=(0.5,5.5),num_iters=(0,20))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "interactive(gradient_descent,\n                       x0=FloatSlider(value=2,min=0.5,max=5.5),\n                       num_iters=IntSlider(value=0,min=0,max=20),\n                       eta=FloatSlider(value=0.1,min=0.01,max=1.0,step=0.01),\n                       tol=fixed(1e-6))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "a = FloatSlider(value=2,min=0.5,max=5.5)\nb = IntSlider(value=0,min=0,max=50)\nc = FloatSlider(value=0.1,min=0.01,max=2.0,step=0.01)\ninteract(gradient_descent,\n                       x0 = a,\n                       num_iters = b,\n                       eta = c,\n                       tol=fixed(1e-6))\ndef achanged(change):\n    b.value = 0\na.observe(achanged,'value')\n\ndef cchanged(change):\n    b.value = 0\nc.observe(cchanged,'value')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def gradient_descent_2(x0, eta=.1, tol=1e-6, num_iters=10):\n    xtheory = np.linspace(0.5, 3, 300)\n    ytheory = f(xtheory)\n    x = [x0]\n    i = 0\n\n    fig = plt.figure(figsize=(12,7))\n    curve = plt.plot(xtheory, ytheory, 'b-')\n    plt.plot(x[-1],f(x[-1]),'ko',markersize=10)\n    while i < num_iters:\n        x_prev = x[-1]\n        grad = df(x_prev)\n        x_curr = x_prev - eta * grad\n        x.append(x_curr)\n        if f(x_curr) > 10:\n            break\n        plt.plot(x_curr,f(x_curr),'ko',markersize=10)\n        plt.plot([x_prev,x_curr],[f(x_prev),f(x_curr)],'k--')\n        \n        if np.abs(x_curr - x_prev) < tol:\n            break\n        i += 1\n    \n    fig.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "a = FloatSlider(value=1.3,min=0.5,max=3,description='x0')\nb = IntSlider(value=0,min=0,max=50,description='num_iters')\nc = FloatSlider(value=0.2,min=0.01,max=2.0,step=0.01,description='eta')\ncontrols = VBox([a,b,c])\nplotwidget = interactive_output(gradient_descent_2, {\n                       'x0':a,\n                       'num_iters':b,\n                       'eta':c,\n                       'tol':fixed(1e-6)});\ndef achanged(change):\n    b.value = 0\na.observe(achanged,'value')\n\ndef cchanged(change):\n    b.value = 0\nc.observe(cchanged,'value')\n\nplay = Play(value=0,min=0,max=1000,step=1,interval=1000,description=\"Press play\",disabled=False)\njslink((play, 'value'), (b, 'value'))\ngradmov = VBox([controls,plotwidget,play])\n\ndisplay(gradmov)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}