{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4a16cba",
      "metadata": {},
      "source": "# Review, Extending the CA Housing Predictions with Trees and Forests"
    },
    {
      "cell_type": "markdown",
      "id": "39876fa0",
      "metadata": {},
      "source": "This notebook extends our previous exercise notebook \"Week03_Exercise_Housing.ipynb\", with my filled-in version being \"Week03_Exercise_Housing_FilledIn.ipynb\"."
    },
    {
      "cell_type": "markdown",
      "id": "68eb1a71",
      "metadata": {},
      "source": "## Review (abbreviated)"
    },
    {
      "cell_type": "markdown",
      "id": "24cb9411",
      "metadata": {},
      "source": "Execute the following cell to import our libraries:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f4e513",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# for data wrangling, plotting, numerical analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# for our data\nfrom sklearn.datasets import fetch_california_housing\n\n# for ML data processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# for our ML models\nfrom sklearn.linear_model import LinearRegression\n\n# for our ML evaluation\nfrom sklearn.metrics import mean_squared_error, r2_score"
    },
    {
      "cell_type": "markdown",
      "id": "9b99c53e",
      "metadata": {},
      "source": "We'll use a dataset from Scikit-Learn:  [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebe9155",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": "california_housing = fetch_california_housing(as_frame=True)\nca_housing_df = california_housing.frame"
    },
    {
      "cell_type": "markdown",
      "id": "32d2cbca",
      "metadata": {},
      "source": "Use the cell below to look at some sample rows of the `ca_housing_df` dataframe:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7212c09",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ca_housing_df.head()"
    },
    {
      "cell_type": "markdown",
      "id": "36cb87a0",
      "metadata": {},
      "source": "Use the `info` method to look at the number of rows & columns, and see whether there are any null values:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480d7ec2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ca_housing_df.info()"
    },
    {
      "cell_type": "markdown",
      "id": "ee5f4450",
      "metadata": {},
      "source": "Make simple histogram plots of all variables (e.g. with `ca_housing_df.hist()`).\n* Are they normally distributed? Bi-modal?  mostly normal with a couple outliers?  uniformly distributed with obvious caps to the allowable range of values?\n* If you'd like, tinker with the number of bins for the histogram, zoom in on the ranges, etc\n* You may also find it useful to change the figure size (e.g. `figsize=(12, 10)` as an input parameter to `hist`) or use `plt.tight_layout()` after the plotting command to keep multiple plots from overlapping"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454b3346",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ca_housing_df.hist(bins=30, figsize=(12, 10))\nplt.tight_layout()"
    },
    {
      "cell_type": "markdown",
      "id": "ba989492",
      "metadata": {},
      "source": "You can get a matrix of correlation coefficients by using the dataframe's `corr()` method.\n* Check that out in the cell below\n* Which variables are most correlated with the target variable of `MedHouseVal`?\n* Which pairs of variables are highly correlated with each other?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de96e44",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ca_housing_df.corr()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c2cefc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.figure(figsize=(8,5))\nsns.heatmap(ca_housing_df.corr(), annot=True)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a01839eb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.figure(figsize=(8,5))\nplt.plot(ca_housing_df['Latitude'], ca_housing_df['Longitude'], 'bo', alpha=0.2)"
    },
    {
      "cell_type": "markdown",
      "id": "616ebd17",
      "metadata": {},
      "source": "Use `train_test_split` to make a training set and test set, where `MedHouseVal` is your target variable and all other variables are your feature variables.\n* You can use `california_housing.data` and `california_housing.target` to get your features and target, or you can use `ca_housing_df.loc[:, ca_housing_df.columns != 'MedHouseVal']` and `ca_housing_df.loc[:, 'MedHouseVal']`  (or other options too)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916ebbbd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(california_housing.data, \n                                                    california_housing.target, \n                                                    test_size=0.2, \n                                                    random_state=42)"
    },
    {
      "cell_type": "markdown",
      "id": "35c55888",
      "metadata": {},
      "source": "We further scale the data.  This gives better convergence and stability properties for some algorithms.\n\n*Remember*: the training data should be used to determine scaling properties, NOT all the data.  We don't want any information about our test data to prematurely \"leak\" into our training set."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b318bbb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Standardize the features\nscaler = StandardScaler()\nscaler.set_output(transform='pandas')\n\n# Use training data for the scaler fit, as well as transformation\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Only use the transform (and not the fit_transform) on the test features\nX_test_scaled = scaler.transform(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d32d34b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33dabfb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train_scaled"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb55947",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train.mean()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95f98fb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train_scaled.mean()"
    },
    {
      "cell_type": "markdown",
      "id": "eefadcfd",
      "metadata": {},
      "source": "In the next cell:\n* train `Linear_Regression` on your training set\n* assess the learned model's performance on the test data using `mean_squared_error`\n* make a plot of the coefficient amplitudes\n  * the coefficient values are stored in the `coef_` attribute of the variable for your `LinearRegression` object"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c5174f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Initialize Linear Regression (without regularization)\nmodel_lr = LinearRegression()\n\n# Train the model\nmodel_lr.fit(X_train_scaled, y_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83e20e6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# We now have a model with learned coefficients:\nprint(f\"Linear Regression (No Regularization) - Intercept (bias) term:\")\nprint(model_lr.intercept_)\nprint(\"Linear Regression (No Regularization) - Coefficients:\")\nprint(model_lr.coef_)"
    },
    {
      "cell_type": "markdown",
      "id": "165975e0",
      "metadata": {},
      "source": "Evaluation:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59548b4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# 'score' requires passing in your feature and target values\n# for the test set\nprint('The score method returns: %.2f' % model_lr.score(X_test_scaled, y_test))\n\n# mean_squared_error and r2_score are metrics that assess predictions against target values\n# so you need to get the predicted values first\ny_pred1 = model_lr.predict(X_test_scaled)\nprint('MSE_lr = %.2f' % mean_squared_error(y_test, y_pred1))\nprint('R2_lr = %.2f' % r2_score(y_test, y_pred1))"
    },
    {
      "cell_type": "markdown",
      "id": "03069640",
      "metadata": {},
      "source": "## Adding Trees"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd857d9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.tree import DecisionTreeRegressor\nfrom sklearn import tree"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82143943",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Inherent Interpretability: Decision Tree Regressor\n# Create and fit a decision tree regressor\n\nmodel_tree = DecisionTreeRegressor(random_state=42, max_depth=3)\nmodel_tree.fit(X_train_scaled, y_train)\n\ny_pred1 = model_tree.predict(X_test_scaled)\nprint('R2_tree_best = %.2f' % r2_score(y_test, y_pred1))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a37def6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Visualize the decision tree (for inherent interpretability)\nplt.figure(figsize=(12,8))\ntree.plot_tree(model_tree, \n               feature_names=california_housing.feature_names, \n               filled=True, \n               rounded=True);"
    },
    {
      "cell_type": "markdown",
      "id": "b46fbd3d",
      "metadata": {},
      "source": "And how do we know what the best value of `max_depth` is? (Or any other hyperparameter?)\n* cross validation!"
    },
    {
      "cell_type": "markdown",
      "id": "6bfcf94b",
      "metadata": {},
      "source": "**Cross Validation Method #1**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2dc74de",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.model_selection import cross_val_score"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3602f77c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "md_range = range(1,20)\nmd_scores = []\nfor md in md_range:\n    model = DecisionTreeRegressor(random_state=42, max_depth=md)\n    loss = cross_val_score(model,\n                           X_train_scaled,\n                           y_train, \n                           cv=5, \n                           scoring='neg_mean_squared_error')\n    md_scores.append(np.sqrt(-loss).mean())\nplt.scatter(md_range, md_scores)\nplt.xlabel('Value of max_depth for Decision Tree Regression')\nplt.ylabel('Cross-Validated RMSE')\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f16f0e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "md_range[md_scores.index(min(md_scores))]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e7ab20",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "md_best = md_range[md_scores.index(min(md_scores))]\n\nmodel_tree_best = DecisionTreeRegressor(random_state=42, max_depth=md_best)\n\nmodel_tree_best.fit(X_train_scaled, y_train)\n\ny_pred1 = model_tree_best.predict(X_test_scaled)\nprint('R2_tree_best = %.2f' % r2_score(y_test, y_pred1))"
    },
    {
      "cell_type": "markdown",
      "id": "4c5507cd",
      "metadata": {},
      "source": "**Cross Validation Method #2**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef38e747",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.model_selection import GridSearchCV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616ffa34",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "cv_grid = GridSearchCV(DecisionTreeRegressor(random_state=42),\n                       param_grid = {\n                           'max_depth' : range(1,20),\n                       })\ncv_grid.fit(X_train_scaled, y_train)\ncv_grid.best_params_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016864b4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred1 = cv_grid.predict(X_test_scaled)\nprint('R2_tree_best = %.2f' % r2_score(y_test, y_pred1))"
    },
    {
      "cell_type": "markdown",
      "id": "6e47096e",
      "metadata": {},
      "source": "# Random Forest"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7abcc22b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.ensemble import RandomForestRegressor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508203c8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model_rf = RandomForestRegressor(n_estimators=500, \n                                max_leaf_nodes=9, \n                                n_jobs=-1,\n                                random_state=42)\n\nmodel_rf.fit(X_train_scaled, y_train)\n\ntest_score = model_rf.score(X_test_scaled, y_test)\nprint(f\"R2 of Random Forest: {test_score:.2f}\")\n\ny_pred1 = model_rf.predict(X_test_scaled)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred1))\nprint(\"RMSE of Random Forest: %f\" % (rmse))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed2017d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.figure(figsize=(12,8))\ntree.plot_tree(model_rf.estimators_[1], \n               feature_names=california_housing.feature_names,\n               filled=True);"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f58e03",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.barh(california_housing.feature_names, \n         model_rf.feature_importances_)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b485c1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "cv_grid = GridSearchCV(RandomForestRegressor(n_jobs=-1,random_state=42),\n                       param_grid = {\n                           'max_depth' : [5,9,15],\n                           'n_estimators' : [100,200]\n                       })\ncv_grid.fit(X_train_scaled, y_train)\ncv_grid.best_params_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8928bf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = cv_grid.predict(X_test_scaled)\nr2score = r2_score(y_test,y_pred)\nprint('R2 of the best Random Forest regressor after CV is %.2f' % (r2score))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6186a059",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.barh(california_housing.feature_names, \n         cv_grid.best_estimator_.feature_importances_)"
    },
    {
      "cell_type": "markdown",
      "id": "2540cb69",
      "metadata": {},
      "source": "And Boosting?\n* we can review at the end if there is interest"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}