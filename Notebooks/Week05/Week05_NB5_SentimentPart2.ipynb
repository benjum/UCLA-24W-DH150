{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b469de05-cc72-4ef5-bb6f-cbb65d155aa9",
      "metadata": {},
      "source": "# Sentiment and Classification, Part 2 "
    },
    {
      "cell_type": "markdown",
      "id": "5fd26cd6",
      "metadata": {},
      "source": "We are now going to do classification of NLTK's movie review dataset with machine learning.  Specifically, we'll use Logistic Regression, and we'll process our corpus of reviews using BoW with a couple different options, as well as using TF-IDF."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf09281",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import pandas as pd\n\nimport nltk\nnltk.download('movie_reviews')\nfrom nltk.corpus import movie_reviews\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8229fea",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "reviews = movie_reviews.fileids()\n\ndf = pd.DataFrame({'review_sentiment': [movie_reviews.categories(review)[0]\n                                        for review in reviews], \n                   'review_text': [movie_reviews.raw(review).replace('\\n','')\n                                   for review in reviews]})\n\ndf.head()"
    },
    {
      "cell_type": "markdown",
      "id": "1844e90b",
      "metadata": {},
      "source": "What happens if we.... completely ignore the sentiment connotations of individual words?  Does it make sense to completely ignore meaning and look at statistical occurrences of words across a given set of texts?"
    },
    {
      "cell_type": "markdown",
      "id": "8b25bae9",
      "metadata": {},
      "source": "# BoW\n\nMake a word-document matrix that contains the word counts for all words across all documents."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90219d9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vectorizer = CountVectorizer(lowercase=True, \n                             stop_words='english', \n                             max_features=1000, \n                             min_df=5, \n                             max_df=0.7)\n\nbag_of_words = vectorizer.fit_transform(df['review_text'])\n\nbag_of_words_df = pd.DataFrame(bag_of_words.toarray(), \n                               columns=vectorizer.get_feature_names_out())\n\nbag_of_words_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e435f5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "non_zero_values = bag_of_words_df.loc[0][bag_of_words_df.loc[0] != 0]\nprint(non_zero_values)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db34b88",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "columns_with_value_1 = bag_of_words_df.columns[bag_of_words_df.loc[0] != 0]\nprint(columns_with_value_1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6278a698",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bag_of_words_df.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4df144",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify=df['review_sentiment'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123fb42f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a79e93f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "pos_records = (y_test == 'pos')\nmodel.score(x_test[pos_records], y_test[pos_records])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d03f87",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "neg_records = (y_test == 'neg')\nmodel.score(x_test[neg_records], y_test[neg_records])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d90c1a0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train.loc[[0]]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780a1e46",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model.predict(x_train.loc[[0]])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b4c495",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": "df['logregSentiment'] = bag_of_words_df.apply(lambda row: model.predict([row]), axis=1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e15dba8",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df.loc[df['review_sentiment']=='pos', 'logregSentiment'].value_counts()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5227395b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df.loc[df['review_sentiment']=='neg', 'logregSentiment'].value_counts()"
    },
    {
      "cell_type": "markdown",
      "id": "d797c698",
      "metadata": {},
      "source": "We used stratification on our target values above.  We could also do shuffling and that would give similar results too:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c0a197",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42,\n                                                    shuffle=True)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83929834",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ac9ef6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_train.value_counts()"
    },
    {
      "cell_type": "markdown",
      "id": "20aa028b",
      "metadata": {},
      "source": "# BoW even simpler\n\nUsing `binary=True`, we simply record whether a word is in the review or not (1 or 0)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf3c765",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vectorizer = CountVectorizer(lowercase=True, \n                             stop_words='english', \n                             max_features=1000, \n                             min_df=5, \n                             max_df=0.7,\n                             binary=True)\n\nbag_of_words = vectorizer.fit_transform(df['review_text'])\n\nbag_of_words_df = pd.DataFrame(bag_of_words.toarray(), \n                               columns=vectorizer.get_feature_names_out())\n\nbag_of_words_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2c0c68",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "non_zero_values = bag_of_words_df.loc[0][bag_of_words_df.loc[0] != 0]\nprint(non_zero_values)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d77ed9c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bag_of_words_df.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978a6d6b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify=df['review_sentiment'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6985c89d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"
    },
    {
      "cell_type": "markdown",
      "id": "140ad453",
      "metadata": {},
      "source": "# BoW with n-grams\n\n`ngram_range=(1,2)` will allow us to retain 1-grams up to 2-grams, for a little bit of context saving."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5cab7c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vectorizer = CountVectorizer(lowercase=True, \n                             stop_words='english', \n                             max_features=1000, \n                             min_df=5, \n                             max_df=0.7,\n                             binary=True,\n                             ngram_range=(1, 2))\n\nbag_of_words = vectorizer.fit_transform(df['review_text'])\n\nbag_of_words_df = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names_out())\n\nbag_of_words_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400c694d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "non_zero_values = bag_of_words_df.loc[0][bag_of_words_df.loc[0] != 0]\nprint(non_zero_values)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d7b686",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bag_of_words_df.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2e984f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify=df['review_sentiment'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de025d7b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"
    },
    {
      "cell_type": "markdown",
      "id": "0c63451b",
      "metadata": {},
      "source": "# TF-IDF\n\nTerm-frequency inverse document frequency uses the word counts but now weighted so as to upweight words that more uniquely distinguish the vocabulary of a text (or subset of texts) relative to the entire corpus."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b10dbf",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vectorizer = TfidfVectorizer(lowercase=True, \n                                        stop_words='english', \n                                        max_features=1000, \n                                        min_df=5, \n                                        max_df=0.5)\n\nbag_of_words = vectorizer.fit_transform(df['review_text'])\n\nbag_of_words_df = pd.DataFrame(bag_of_words.toarray(), \n                               columns=vectorizer.get_feature_names_out())\n\nbag_of_words_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690edaef",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "non_zero_values = bag_of_words_df.loc[0][bag_of_words_df.loc[0] != 0]\nprint(non_zero_values)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c6670b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bag_of_words_df.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62bf83fa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify=df['review_sentiment'])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fc2f63",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = LogisticRegression()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)"
    },
    {
      "cell_type": "markdown",
      "id": "5c406cc0-cff7-444f-b971-ad336a4d0b23",
      "metadata": {},
      "source": "## Naive Bayes"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af659473-ae24-43d9-91b1-e7cfaea07b3e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df"
    },
    {
      "cell_type": "markdown",
      "id": "fbf58074",
      "metadata": {},
      "source": "We'll use the simple BoW, where only word occurrences are recorded."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcbb1d3d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vectorizer = CountVectorizer(lowercase=True, \n                             stop_words='english', \n                             max_features=1000, \n                             min_df=5, \n                             max_df=0.7,\n                             binary=True)\n\nbag_of_words = vectorizer.fit_transform(df['review_text'])\n\nbag_of_words_df = pd.DataFrame(bag_of_words.toarray(), \n                               columns=vectorizer.get_feature_names_out())\n\nbag_of_words_df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f902772b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bag_of_words_df.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cd862e",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train, x_test, y_train, y_test = train_test_split(bag_of_words_df, \n                                                    df['review_sentiment'], \n                                                    test_size=0.2, \n                                                    random_state=42, \n                                                    stratify=df['review_sentiment'])"
    },
    {
      "cell_type": "markdown",
      "id": "bc0444c5",
      "metadata": {},
      "source": "NLTK has a module `NaiveBayesClassifier`.  Rather than using `fit` as we are used to from scikit-learn, here we use the `train` method.  Furthermore, the data passed into the `train` method has both the independent variable (the review's feature vector) and the dependent variable (the sentiment class)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13113f7c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d20145",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_train.loc[0].to_dict()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53c9c97",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_train.iloc[1]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f86c859",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features = []\nfor i in range(x_train.shape[0]):\n    features.append([x_train.iloc[i].to_dict(), y_train.iloc[i]])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9359f5c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "trainedClassifier = nltk.NaiveBayesClassifier.train(features)"
    },
    {
      "cell_type": "markdown",
      "id": "8da0f764",
      "metadata": {},
      "source": "Now that we have trained our classifier, we can use it to predict the sentiment score of any review.\n\nTo make a prediction, we need to convert the review into a feature vector and then pass that feature vector into our trained classifier to get the prediction.\n\nThe following functions carries out those two steps:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848a5870",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "def naiveBayesSentimentCalculator(review):\n    problemFeatureVector = review.to_dict()\n    return trainedClassifier.classify(problemFeatureVector)"
    },
    {
      "cell_type": "markdown",
      "id": "ad988075",
      "metadata": {},
      "source": "Here is a test example:"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc67bbd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "x_test.iloc[0]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4466f12b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "naiveBayesSentimentCalculator(x_test.iloc[0])"
    },
    {
      "cell_type": "markdown",
      "id": "246cf452",
      "metadata": {},
      "source": "To quantify how our classifier performs, we now pass in the test data to produce predicted sentiment scores that we can compare against the actual test data's ground-truth sentiment scores."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3c05c0f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "[naiveBayesSentimentCalculator(review) for k,review in x_test.iterrows()]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1094c4bc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "accuracy_score(y_test, [naiveBayesSentimentCalculator(review) for k,review in x_test.iterrows()])"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}