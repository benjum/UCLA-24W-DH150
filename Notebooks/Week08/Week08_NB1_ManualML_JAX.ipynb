{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1153be-266b-43c4-82a9-5b6ed62b3863",
   "metadata": {},
   "source": [
    "![JAX](https://jax.readthedocs.io/en/latest/_static/jax_logo_250px.png)\n",
    "\n",
    "\"JAX is Autograd and XLA, brought together for high-performance numerical computing.\"\n",
    "* https://jax.readthedocs.io/en/latest\n",
    "\n",
    "You may need to install `jaxlib`.  If you've installed Tensorflow, chances are that you've already also installed `jax` as one of Tensorflow's dependencies, but `jaxlib` is also still required here.\n",
    "\n",
    "Acknowledgements for this notebook go to:\n",
    "* https://colindcarroll.com/2019/04/06/exercises-in-automatic-differentiation-using-autograd-and-jax/\n",
    "* https://coax.readthedocs.io/en/latest/examples/linear_regression/jax.html\n",
    "* https://coderzcolumn.com/tutorials/artificial-intelligence/guide-to-create-simple-neural-networks-using-jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816e2d0-5dbb-4831-a793-fb2b8e6b383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a5762-dcf6-424d-9f69-a64218326826",
   "metadata": {},
   "source": [
    "## Simple automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb248f3-86c6-4b84-b717-2064d0e48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = jnp.linspace(-4, 4, 1000)\n",
    "\n",
    "my_func = jnp.tanh\n",
    "\n",
    "ax.plot(x, my_func(x))\n",
    "\n",
    "# ax.plot(x, grad(my_func)(x)) -> won't work\n",
    "# The gradient needs to be vectorized\n",
    "# to be applied across all elements of x\n",
    "\n",
    "ax.plot(x, vmap(grad(my_func))(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c4f31-8357-4284-a6cc-64a53e1f0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrad = grad(my_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0fb2c-08bb-447d-9794-7838d8b15742",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrad(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd935f-72e6-44ce-9e60-dfda4414eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = jnp.linspace(-2 * jnp.pi, 2 * jnp.pi, 1000)\n",
    "\n",
    "y = jnp.cos\n",
    "d1y = grad(y)\n",
    "d2y = grad(grad(y))\n",
    "\n",
    "ax.plot(x, y(x), 'k-', lw=4)\n",
    "ax.plot(x, vmap(d1y)(x), 'b-')\n",
    "ax.plot(x, -vmap(d2y)(x), 'w--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dadd4-06a2-47f1-964c-253aad30ad1b",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bb04a-45a8-44d6-9033-df1df665937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645fc52-cb04-4d6b-ae91-b69c09539d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our dataset -- make_regression make a random regression problem\n",
    "X, y = make_regression(n_features=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50b597-606f-4a3c-93ea-a8fa4fecfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214e73e-3741-4241-82cc-728c1e9eb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d462e31-432c-476e-8ad7-37c8338c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(12,4))\n",
    "for i in range(3):\n",
    "  ax[i].scatter(X_train[:, i], y_train, c='b')\n",
    "  ax[i].scatter(X_test[:, i], y_test, c='g')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4b2026-7dff-476e-9158-fe475e301970",
   "metadata": {},
   "source": [
    "### What steps do we need?\n",
    "\n",
    "* Using the current parameters, calculate $\\hat{y} = wx + b$\n",
    "* Calculate the resulting loss score: [$J = $mean$(\\hat{y} - y_{actual})^2$]\n",
    "* Update the weights using gradient descent: $w_{i+1} = w_{i} - \\alpha\\frac{\\partial J}{\\partial w_i}$\n",
    "  * and update both $w$ and $b$ this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12416a0b-e008-4199-8d52-31674c33112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model weights\n",
    "params = {\n",
    "    'w': jnp.zeros(X.shape[1:]),\n",
    "    'b': 0.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74501dfa-eba1-4e98-82de-528479fee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.array([1.,2.,3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d28d31-e4d4-4faa-a9bd-4958328dc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e5750-cc9f-4681-a6a9-e03c4781414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, X):\n",
    "    return jnp.dot(X, params['w']) + params['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318a8f5-516d-4771-baf5-ebf1d13252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, X, y):\n",
    "    err = forward(params, X) - y\n",
    "    return jnp.mean(jnp.square(err))  # mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79e678-e607-4697-a9be-ad5c1d36769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = grad(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58218db-f0cd-4183-8f6e-e2cc2321e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4270a-0e9f-4195-9a2a-e56aead8e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params, grads):\n",
    "    \n",
    "    for i in range(len(params['w'])):\n",
    "        newval = params['w'][i] - 0.05 * grads['w'][i]\n",
    "        params['w'] = params['w'].at[i].set(newval)\n",
    "    \n",
    "    params['b'] = params['b'] - 0.05 * grads['b']\n",
    "\n",
    "    # a better way:\n",
    "    # return jax.tree_map(lambda p, g: p - 0.05 * g, params, grads)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa00ea2-ba09-4a0a-80ca-ec48c7959c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main training loop\n",
    "for _ in range(100):\n",
    "    loss = loss_fn(params, X_train, y_train)\n",
    "    print(loss)\n",
    "\n",
    "    grads = grad_fn(params, X_train, y_train)\n",
    "    params = update(params, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93588e46-b7f4-47bc-a5a9-2e5e98a075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143eb1f7-a25a-4e2d-a681-8030df71411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "test_preds = forward(params, X_test)\n",
    "train_preds = forward(params, X_train)\n",
    "print(\"Test  MSE Score : {:.2f}\".format(loss_fn(params, X_test, y_test)))\n",
    "print(\"Train MSE Score : {:.2f}\".format(loss_fn(params, X_train, y_train)))\n",
    "print(\"Test  R^2 Score : {:.2f}\".format(r2_score(test_preds.squeeze(), y_test)))\n",
    "print(\"Train R^2 Score : {:.2f}\".format(r2_score(train_preds.squeeze(), y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221d144-692f-4976-9f94-f3981fd00d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127e792-85a4-4387-95ca-83473a66561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f611c85-2f0f-4b05-8b55-82f4dae6889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41582a7-4ad9-4506-9200-cc9a53944a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dab1ca-8d3f-4cf8-9069-1a8a43b6954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "train_preds = model.predict(X_train)\n",
    "print(\"Test  MSE Score : {:.2f}\".format(mean_squared_error(test_preds, y_test)))\n",
    "print(\"Train MSE Score : {:.2f}\".format(mean_squared_error(train_preds, y_train)))\n",
    "print(\"Test  R^2 Score : {:.2f}\".format(r2_score(test_preds, y_test)))\n",
    "print(\"Train R^2 Score : {:.2f}\".format(r2_score(train_preds, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ba81c-adb4-4af7-aa7a-7498e776b183",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### What steps do we need *for logistic regression*?\n",
    "\n",
    "* Using the current parameters, calculate $\\hat{y} = 1 / (1 + e^{-(wx+b)})$\n",
    "* Calculate the resulting loss score: [$J = $mean$(- y_{actual} \\log(\\hat{y}) - (1 - y_{actual})\\log(1 - \\hat{y}))$]\n",
    "* Update the weights using gradient descent: $w_{i+1} = w_{i} - \\alpha\\frac{\\partial J}{\\partial w_i}$\n",
    "  * and update both $w$ and $b$ this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013461e4-61d8-4436-9d03-50c794a42d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8e749-babc-424a-92fb-f9bd2bf01ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd0a0c-1dc4-4fc7-ab57-1e864f7753d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bee82-0eb5-4579-b687-207e2ae3bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20151f36-4a4b-4d0e-b74c-ee258adc9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model weights\n",
    "params = {\n",
    "    'w': jnp.zeros(X.shape[1:]),\n",
    "    'b': 0.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7bbe7-e929-4ee9-9000-ec16e318909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101ffa4-c9ac-48c6-ac92-439edb21e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['w'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef19b8-d3c8-4c97-a352-e478538d4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, X):\n",
    "    #return jnp.dot(X, params['w']) + params['b']\n",
    "    return 1 / (1 + jnp.exp(-jnp.dot(X, params['w']) - params['b']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e786e99-e000-4b22-8447-15e875eee7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(params,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d7c82-380d-4a20-a157-d53cdfbcaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, X, y):\n",
    "    preds = forward(params, X)\n",
    "    return (- y * jnp.log(preds) - (1 - y) * jnp.log(1 - preds)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987f3f4-ad46-4cf9-9d15-c9ff61489074",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = grad(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d721-51e4-40a8-a8f7-4d9e39758657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params, grads):\n",
    "\n",
    "    for i in range(len(params['w'])):\n",
    "        newval = params['w'][i] - 0.05 * grads['w'][i]\n",
    "        params['w'] = params['w'].at[i].set(newval)\n",
    "\n",
    "    params['b'] = params['b'] - 0.05 * grads['b']\n",
    "    \n",
    "    # Better way\n",
    "    # return jax.tree_map(lambda p, g: p - 0.05 * g, params, grads)\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65556a26-5280-4772-a15f-3b5423bcf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main training loop\n",
    "for _ in range(100):\n",
    "    loss = loss_fn(params, X_test, y_test)\n",
    "    print(loss)\n",
    "\n",
    "    grads = grad_fn(params, X_train, y_train)\n",
    "    params = update(params, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49906b58-e6f7-4b3d-9532-e9e138f0f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c80c1-cd5a-4d11-8848-e364af021faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = forward(params, X_train)\n",
    "train_preds = jnp.where(train_preds > 0.5, 1, 0)\n",
    "\n",
    "test_preds = forward(params, X_test)\n",
    "test_preds = jnp.where(test_preds > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f68fe-8e1a-4ceb-a81a-875e5fe6d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041fd359-12d2-42f8-b863-adeb307a92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480bef2-b044-4d0f-8b96-6483d431419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39002f51-a809-4594-9159-5f4d150ae32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a8552-7b83-40a1-84b1-82f3212fe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25cc2e-26fa-48d4-ba21-3ede47776e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec59679-f8d8-44f6-91b3-af48358d4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acc0a7-568c-42e7-b682-34d568a4bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40791ef0-4225-4ef3-9541-a2ff53bb6e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555897e6-d06f-4fea-98cf-541a3e47c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891fff1-a8a2-4403-bc53-0a90dc4d1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661609a7-b2e3-4d95-a6af-e5bd5ae34f55",
   "metadata": {},
   "source": [
    "# Neural Network Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9679d-f54d-4364-9e9b-d487945e148c",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from sklearn.datasets import load_boston\n",
    "#from sklearn.datasets import fetch_california_housing\n",
    "#X,Y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b4c06-3e03-45ea-9d31-3cb948fe7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#X, Y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "Y = raw_df.values[1::2, 2]\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=123)\n",
    "\n",
    "#from tensorflow.keras.datasets import boston_housing\n",
    "#(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c939e8-365f-4d43-bd63-0b87db841833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = jnp.array(X_train, dtype=jnp.float32),\\\n",
    "                                   jnp.array(X_test, dtype=jnp.float32),\\\n",
    "                                   jnp.array(Y_train, dtype=jnp.float32),\\\n",
    "                                   jnp.array(Y_test, dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c988e-0f35-4787-bd9a-1602fdc3da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278afc6-5035-4677-b706-ab44f0ca5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8471c14-725a-483f-87cb-80c2aa13a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555f090-6a0f-47e0-a9df-5f412d2cc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(layer_sizes, seed):\n",
    "    weights = []\n",
    "\n",
    "    for i, units in enumerate(layer_sizes):\n",
    "        if i==0:\n",
    "            w = jax.random.uniform(key=seed, \n",
    "                                   shape=(units, features), \n",
    "                                   minval=-1.0, maxval=1.0, \n",
    "                                   dtype=jnp.float32)\n",
    "        else:\n",
    "            w = jax.random.uniform(key=seed, \n",
    "                                   shape=(units, layer_sizes[i-1]), \n",
    "                                   minval=-1.0, maxval=1.0,\n",
    "                                   dtype=jnp.float32)\n",
    "\n",
    "        b = jax.random.uniform(key=seed, \n",
    "                               shape=(units,), \n",
    "                               minval=-1.0, maxval=1.0, \n",
    "                               dtype=jnp.float32)\n",
    "\n",
    "        weights.append([w,b])\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02892d34-5139-4ea3-9425-930e8d98012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(123)\n",
    "\n",
    "weights = InitializeWeights([64,64,1], seed)\n",
    "\n",
    "for w in weights:\n",
    "    print(w[0].shape, w[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff239fe-dd8c-43de-9d0e-eb1af1e76f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    return jnp.maximum(x, jnp.zeros_like(x)) # max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab18fb2-febe-4072-a492-fa9f76a9ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "\n",
    "x = jnp.array([-1,0,1,-2,4,-6,5])\n",
    "Relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6acff-db1f-4df5-bb6f-62bbe780e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "\n",
    "x = jnp.array([[-1,0,1,-2,4,-6,5],\n",
    "               [1,2,4,-5,-6,7,9]])\n",
    "Relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464419-6d5b-4fff-a4fb-4731a99b5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(weights, input_data, activation):\n",
    "    w, b = weights\n",
    "    out = jnp.dot(input_data, w.T) + b\n",
    "    return activation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02380ca8-475e-408f-9c2d-745512336814",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d358d-dea3-4c53-96ab-976fe40c5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0][0].shape, weights[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f71dcb-7daf-4185-b18d-9413b5cb02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPass(weights, input_data):\n",
    "    layer_out = input_data\n",
    "\n",
    "    for i in range(len(weights[:-1])):\n",
    "        layer_out = LinearLayer(weights[i], layer_out, Relu)\n",
    "\n",
    "    activation_self = lambda x: x\n",
    "    preds = LinearLayer(weights[-1], layer_out, activation_self)\n",
    "    \n",
    "    # can check shape here\n",
    "    # squeeze below will get rid of dims that have length 1\n",
    "    # see e.g. # help(jnp.zeros(3).squeeze)\n",
    "    # print(preds.shape)\n",
    "\n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84b127-ab2b-4bd1-a765-ee670fd478d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ForwardPass(weights, X_train)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb3887-f379-4775-b261-13192ed83857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanSquaredErrorLoss(weights, input_data, actual):\n",
    "    preds = ForwardPass(weights, input_data)\n",
    "    return jnp.power(actual - preds, 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a07ff-e08a-43d1-bc9c-0eb9a835f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateGradients(weights, input_data, actual):\n",
    "    Grad_MSELoss = grad(MeanSquaredErrorLoss)\n",
    "    gradients = Grad_MSELoss(weights, input_data, actual)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13730456-10c2-48eb-8d34-c81469884985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(weights, X, Y, learning_rate, epochs):\n",
    "    for i in range(epochs):\n",
    "        loss = MeanSquaredErrorLoss(weights, X, Y)\n",
    "        gradients = CalculateGradients(weights, X, Y)\n",
    "\n",
    "        ## Update Weights\n",
    "        for j in range(len(weights)):\n",
    "            weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "            weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "        if i%100 ==0: ## Print MSE every 100 epochs\n",
    "            print(\"MSE : {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7e5c3-4cfd-43c7-bd7f-70eb84c5262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(42)\n",
    "learning_rate = jnp.array(1/1e3)\n",
    "epochs = 1500\n",
    "layer_sizes = [64,64,1]\n",
    "\n",
    "weights = InitializeWeights(layer_sizes, seed)\n",
    "\n",
    "TrainModel(weights, X_train, Y_train, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f6430-716a-4114-802e-d64f0e8a39c9",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2176fd-1b86-490a-b682-b394b03c9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = ForwardPass(weights, X_train)\n",
    "\n",
    "train_preds[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e45160-6511-4a88-9c08-b110b5583169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = ForwardPass(weights, X_test)\n",
    "\n",
    "test_preds[:5], Y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaffe84-230f-43f6-9e51-8b77fb97233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test  MSE Score : {:.2f}\".format(MeanSquaredErrorLoss(weights, X_test, Y_test)))\n",
    "print(\"Train MSE Score : {:.2f}\".format(MeanSquaredErrorLoss(weights, X_train, Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239739d-9911-4ae4-b5cd-76e0d5a06943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test  R^2 Score : {:.2f}\".format(r2_score(test_preds.squeeze(), Y_test)))\n",
    "print(\"Train R^2 Score : {:.2f}\".format(r2_score(train_preds.squeeze(), Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f410e-3f12-4e64-a452-3cd08951a34a",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "\n",
    "In the below, the material is extended to consider:\n",
    "* training with batches of data\n",
    "* neural net for classification\n",
    "  * this can again be thought of rather simply: use a different loss function, a different activation function for the final layer, and a different metric for assessing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3edf0a-cd13-4320-a718-a65086af7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we found better performance for 130 epochs\n",
    "# since this is overfitting\n",
    "\n",
    "# We also did this in batches rather than using all our data at once\n",
    "\n",
    "def UpdateWeights(learning_rate, weights, gradients):\n",
    "    for j in range(len(weights)): ## Update Weights\n",
    "        weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "        weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "def TrainModelInBatches(weights, X, Y, learning_rate, epochs, batch_size=32):\n",
    "    for i in range(epochs):\n",
    "        batches = jnp.arange((X.shape[0]//batch_size)+1) ### Batch Indices\n",
    "\n",
    "        losses = [] ## Record loss of each batch\n",
    "        for batch in batches:\n",
    "            if batch != batches[-1]:\n",
    "                start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n",
    "            else:\n",
    "                start, end = int(batch*batch_size), None\n",
    "\n",
    "            X_batch, Y_batch = X[start:end], Y[start:end] ## Single batch of data\n",
    "\n",
    "            loss = MeanSquaredErrorLoss(weights, X_batch, Y_batch) ## Loss of batch\n",
    "            gradients = CalculateGradients(weights, X_batch, Y_batch)\n",
    "            losses.append(loss) ## Record Loss\n",
    "\n",
    "            UpdateWeights(learning_rate, weights, gradients) ## Update Weights\n",
    "\n",
    "        if i % 100 == 0: ## Print MSE every 100 epochs\n",
    "            print(\"MSE : {:.2f}\".format(jnp.array(losses).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a357fd-6af8-4bf8-9bf5-2d8fd95e1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(42)\n",
    "learning_rate = jnp.array(1/1e3)\n",
    "epochs = 130\n",
    "layer_sizes = [64,64,1]\n",
    "\n",
    "weights = InitializeWeights(layer_sizes, seed)\n",
    "\n",
    "TrainModelInBatches(weights, X_train, Y_train, learning_rate, epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf46aeb-4b33-44cc-b2a7-6b1740ca64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = ForwardPass(weights, X_test)\n",
    "train_preds = ForwardPass(weights, X_train)\n",
    "print(\"Test  MSE Score : {:.2f}\".format(MeanSquaredErrorLoss(weights, X_test, Y_test)))\n",
    "print(\"Train MSE Score : {:.2f}\".format(MeanSquaredErrorLoss(weights, X_train, Y_train)))\n",
    "print(\"Test  R^2 Score : {:.2f}\".format(r2_score(test_preds.squeeze(), Y_test)))\n",
    "print(\"Train R^2 Score : {:.2f}\".format(r2_score(train_preds.squeeze(), Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a90ca-45f4-4eea-aaa9-d66e70b9d2e2",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9777db1-f57f-4c1f-a27d-7fb8e1e4e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, stratify=Y, random_state=123)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = jnp.array(X_train, dtype=jnp.float32),\\\n",
    "                                   jnp.array(X_test, dtype=jnp.float32),\\\n",
    "                                   jnp.array(Y_train, dtype=jnp.float32),\\\n",
    "                                   jnp.array(Y_test, dtype=jnp.float32)\n",
    "\n",
    "samples, features = X_train.shape\n",
    "classes = jnp.unique(Y)\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610fd13-0387-4a03-963d-cedf90c31e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, features, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5764a-8ff7-446d-a0f4-c151d3184326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Neural Network Regression Section\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f4e46-b0d9-4040-8eef-a735a1a1dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Neural Network Regression Section\n",
    "\n",
    "def InitializeWeights(layer_sizes, seed):\n",
    "    weights = []\n",
    "\n",
    "    for i, units in enumerate(layer_sizes):\n",
    "        if i==0:\n",
    "            w = jax.random.uniform(key=seed, \n",
    "                                   shape=(units, features), \n",
    "                                   minval=-1.0, maxval=1.0, \n",
    "                                   dtype=jnp.float32)\n",
    "        else:\n",
    "            w = jax.random.uniform(key=seed, \n",
    "                                   shape=(units, layer_sizes[i-1]), \n",
    "                                   minval=-1.0, maxval=1.0,\n",
    "                                   dtype=jnp.float32)\n",
    "\n",
    "        b = jax.random.uniform(key=seed, \n",
    "                               shape=(units,), \n",
    "                               minval=-1.0, maxval=1.0, \n",
    "                               dtype=jnp.float32)\n",
    "\n",
    "        weights.append([w,b])\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e2cb2-72c1-476c-9d48-2906840e2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Neural Network Regression Section\n",
    "\n",
    "def Relu(x):\n",
    "    return jnp.maximum(x, jnp.zeros_like(x)) # max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd10700-657a-4e50-bae7-0e3aa81a0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New!\n",
    "# We need this for the final output layer\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return 1 / (1 + jnp.exp(-1 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81916698-cfa6-44c4-ae55-d33a4193b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Neural Network Regression Section\n",
    "\n",
    "def LinearLayer(weights, input_data, activation):\n",
    "    w, b = weights\n",
    "    out = jnp.dot(input_data, w.T) + b\n",
    "    return activation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287ad7e-600d-4e71-b741-3f34f7f85f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The activation function for the output layer is new here\n",
    "\n",
    "def ForwardPass(weights, input_data):\n",
    "    layer_out = input_data\n",
    "\n",
    "    for i in range(len(weights[:-1])):\n",
    "        layer_out = LinearLayer(weights[i], layer_out, Relu)\n",
    "\n",
    "    # not needed -> activation_self = lambda x: x\n",
    "    preds = LinearLayer(weights[-1], layer_out, Sigmoid)\n",
    "    \n",
    "    return preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fab1b7-7b23-4497-a93a-8321e8a73341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than MSE for Loss Function....\n",
    "# def MeanSquaredErrorLoss(weights, input_data, actual):\n",
    "#     preds = ForwardPass(weights, input_data)\n",
    "#     return jnp.power(actual - preds, 2).mean()\n",
    "\n",
    "# We use negative log loss function, appropriate to the binary cross entropy\n",
    "def NegLogLoss(weights, input_data, actual):\n",
    "    preds = ForwardPass(weights, input_data)\n",
    "    return (- actual * jnp.log(preds) - (1 - actual) * jnp.log(1 - preds)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9875e-c160-4d98-80b6-5456692e4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateGradients(weights, input_data, actual):\n",
    "    \n",
    "    # Previsou for regression:\n",
    "    # Grad_MSELoss = jax.grad(MeanSquaredErrorLoss)\n",
    "    # gradients = Grad_MSELoss(weights, input_data, actual)\n",
    "    \n",
    "    # Now for classification:\n",
    "    Grad_NegLogLoss = grad(NegLogLoss)\n",
    "    gradients = Grad_NegLogLoss(weights, input_data, actual)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac1ae4-3f98-4f8e-adaf-47b3c619b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(weights, X, Y, learning_rate, epochs):\n",
    "    for i in range(epochs):\n",
    "        # loss = MeanSquaredErrorLoss(weights, X, Y)\n",
    "        loss = NegLogLoss(weights, X, Y)\n",
    "        gradients = CalculateGradients(weights, X, Y)\n",
    "\n",
    "        ## Update Weights\n",
    "        for j in range(len(weights)):\n",
    "            weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "            weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "        if i%100 ==0: ## Print MSE every 100 epochs\n",
    "            # print(\"MSE : {:.2f}\".format(loss))\n",
    "            print(\"NegLogLoss : {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d525b-f177-4c1a-ac1d-36571b322a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as Neural Network Regression Section\n",
    "\n",
    "seed = jax.random.PRNGKey(42)\n",
    "learning_rate = jnp.array(1/1e2)\n",
    "epochs = 1500\n",
    "layer_sizes = [5,10,15,1]\n",
    "\n",
    "weights = InitializeWeights(layer_sizes, seed)\n",
    "\n",
    "TrainModel(weights, X_train, Y_train, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d326d-d3df-4e1c-963a-d54d82a72bbb",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc49192-c519-46bd-9432-ce77b7c131f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = ForwardPass(weights, X_train)\n",
    "\n",
    "train_preds = (train_preds > 0.5).astype(jnp.float32)\n",
    "\n",
    "train_preds[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ded6f3c-b6f6-444b-9866-8cadc6d87965",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = ForwardPass(weights, X_test)\n",
    "\n",
    "test_preds = (test_preds > 0.5).astype(jnp.float32)\n",
    "\n",
    "test_preds[:5], Y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded3cd4-d3f2-4a25-a384-1b1aa3bcfd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test  NegLogLoss Score : {:.2f}\".format(NegLogLoss(weights, X_test, Y_test)))\n",
    "print(\"Train NegLogLoss Score : {:.2f}\".format(NegLogLoss(weights, X_train, Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de6599-1916-4df8-a067-7142ce01c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Accuracy : {:.2f}\".format(accuracy_score(Y_train, train_preds)))\n",
    "print(\"Test  Accuracy : {:.2f}\".format(accuracy_score(Y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69906a06-e6de-44e1-8783-5f964f859bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateWeights(learning_rate, weights, gradients):\n",
    "    for j in range(len(weights)): ## Update Weights\n",
    "        weights[j][0] -= learning_rate * gradients[j][0] ## Update Weights\n",
    "        weights[j][1] -= learning_rate * gradients[j][1] ## Update Biases\n",
    "\n",
    "def TrainModelInBatches(weights, X, Y, learning_rate, epochs, batch_size=32):\n",
    "    for i in range(epochs):\n",
    "        batches = jnp.arange((X.shape[0]//batch_size)+1) ### Batch Indices\n",
    "\n",
    "        losses = [] ## Record loss of each batch\n",
    "        for batch in batches:\n",
    "            if batch != batches[-1]:\n",
    "                start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n",
    "            else:\n",
    "                start, end = int(batch*batch_size), None\n",
    "\n",
    "            X_batch, Y_batch = X[start:end], Y[start:end] ## Single batch of data\n",
    "\n",
    "            loss = NegLogLoss(weights, X_batch, Y_batch)\n",
    "            gradients = CalculateGradients(weights, X_batch, Y_batch)\n",
    "            losses.append(loss) ## Record Loss\n",
    "\n",
    "            UpdateWeights(learning_rate, weights, gradients) ## Update Weights\n",
    "\n",
    "        if i % 100 == 0: ## Print LogLoss every 100 epochs\n",
    "            print(\"NegLogLoss : {:.2f}\".format(jnp.array(losses).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a353826-afc8-4e7c-81b2-74604df7991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = jax.random.PRNGKey(42)\n",
    "learning_rate = jnp.array(1/1e3)\n",
    "epochs = 1000\n",
    "\n",
    "layer_sizes = [5,10,15,1]\n",
    "\n",
    "weights = InitializeWeights(layer_sizes, seed)\n",
    "\n",
    "TrainModelInBatches(weights, X_train, Y_train, learning_rate, epochs, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1193375-5d95-400e-b9ee-614d267926de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = ForwardPass(weights, X_test)\n",
    "train_preds = ForwardPass(weights, X_train)\n",
    "print(\"Test  NegLogLoss Score : {:.2f}\".format(NegLogLoss(weights, X_test, Y_test)))\n",
    "print(\"Train NegLogLoss Score : {:.2f}\".format(NegLogLoss(weights, X_train, Y_train)))\n",
    "print(\"Test  Accuracy Score : {:.2f}\".format(accuracy_score(test_preds.squeeze(), Y_test)))\n",
    "print(\"Train Accuracy Score : {:.2f}\".format(accuracy_score(train_preds.squeeze(), Y_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
