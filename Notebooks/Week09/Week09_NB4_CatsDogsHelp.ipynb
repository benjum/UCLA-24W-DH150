{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5f6b6c-e8c7-4fa1-95f7-880e66c46830",
   "metadata": {},
   "source": [
    "# Cats vs Dogs -- with help from a pre-trained image classification model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61602b9-dadc-4e3d-ab17-c45a1ba2b643",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/benjum/UCLA-24W-DH150/main/Data/cat-dog-data/test/cat/cat.1500.jpg\" width=\"250px\"/> <img src=\"https://raw.githubusercontent.com/benjum/UCLA-24W-DH150/main/Data/cat-dog-data/test/dog/dog.1500.jpg\" width=\"250px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9deb23d-7f8b-46a3-9032-3aa37350d462",
   "metadata": {},
   "source": [
    "#### We're going to use TensorFlow and Convolutional Neural Networks to identify whether a picture is a dog or a cat.\n",
    "\n",
    "Side-note:  I think the dataset is biased against cats, because most of the cats I've looked at in this dataset look crazy, a bit ugly, or like they totally have it out for the dogs!\n",
    "\n",
    "This dataset is a subset of the data that can be obtained at [Kaggle's Dogs Vs Cats page](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "\n",
    "The code below was motivated by Chollet's Deep Learning with Python book, in which you will find many, many more interesting details and tidbits about doing deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25feba02-7adf-40f4-b7e8-08c1c79d495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929f9f1-24db-470a-8169-cad371f50b17",
   "metadata": {},
   "source": [
    "Special note:  The below can take a long time to run if you only run it using your computer's CPU.  It is highly recommended that you get TensorFlow running on your GPUs if you want to reproduce the cell execution below.  I (B. Winjum) ran this on my Mac M1 and am doing this with TensorFlow 2.13 (along with tensorflow-metal) so that I can run on a GPU.  If you need help running this notebook and/or getting tensorflow running on your local GPU, please reach out for assistance as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac9a55-3e84-46eb-b79a-334e5b5b0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061dd3d-0791-4e8d-8a50-9316d82c0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bafc2-5805-4593-838b-639021289f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa032d6-3d69-41b8-bb6f-845ffa577551",
   "metadata": {},
   "source": [
    "## Getting our data\n",
    "\n",
    "Our data images are in folders that are already split up into training, test, and validation sets.  Furthermore, they are aleady split up into cat and dog folders.\n",
    "\n",
    "The following image_dataset_from_directory gets class labels based on whether the images are retrieved from these \"cat\" or \"dog\" folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e98d3e-75aa-45dd-8d88-850309479a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec79054-3acb-4687-b3b8-39f97f6b21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(os.getcwd(), \"..\", \"..\", \"Data\", \"cat-dog-data\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552767ec-47ff-4832-89cc-9342a92ec330",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    os.path.join(os.getcwd(), \"..\", \"..\", \"Data\", \"cat-dog-data\", \"train\"),\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    os.path.join(os.getcwd(), \"..\", \"..\", \"Data\", \"cat-dog-data\", \"validation\"),\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    os.path.join(os.getcwd(), \"..\", \"..\", \"Data\", \"cat-dog-data\", \"test\"),\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a5149-64a3-47ab-bf06-9babbe0cf463",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.unbatch()\n",
    "a = list(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f6eb1-1263-4e4f-a3a5-1960515bfb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49330ec-3181-4287-b419-4877c18185fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd77c4-cdfa-4ed6-b157-41cc9e453003",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8ad96-c3fb-4bcd-866d-89b16ca2e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2][0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46bccb-f5bd-4c03-b09b-5cf3aae51bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4dcaf-d6e1-4311-b4c1-7cdf41105949",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2\n",
    "print(\"The label for image\",b,\"is\",a[b][1].numpy())\n",
    "print(\"The picture for image\",b,\"is\")\n",
    "plt.imshow(a[b][0].numpy().astype('int32'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80feb5d-3280-487e-a3ce-7846d20ee4bb",
   "metadata": {},
   "source": [
    "# Using pre-trained model\n",
    "\n",
    "We will try using a pre-trained model available through Keras Applications.  \"Keras Applications are deep learning models that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.\"\n",
    "* https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d88de-4ec7-44b2-9dc5-a571d69c60d0",
   "metadata": {},
   "source": [
    "## Feature extraction without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f1274-65af-4e9a-98db-236900e82505",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fee91-8e7e-4866-bb38-61a20d4776f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00acb7-3b23-47b2-8a1d-452eb35235ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "  \n",
    "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels =  get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c97628-cd7f-4f3e-bda4-b480ac195424",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd45ac6-4cec-4a3e-871f-1c97a4c684e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "  \n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        save_weights_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594d11d-c159-4ca6-83e7-a6c631ebb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd43d4-622b-41cd-a373-92f92841a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4262d-4346-4126-81b3-d66e5ab97710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"feature_extraction.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cbee3-430a-4ae3-98ef-3900ed8fa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4e5e6-46fa-45c9-855e-1dd9c4027315",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea203acc-4be0-4ce7-aec5-a450e9f61583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a4695-e135-4b56-8505-34af6963ba5e",
   "metadata": {},
   "source": [
    "## Feature extraction with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e182010-321a-4478-bbba-6414fe1aea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base  = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9517aff-45b3-4b59-80f8-1bfd5ba72e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "len(conv_base.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d4010-0fea-4126-acbc-533e797b18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False\n",
    "len(conv_base.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecd798-5b58-483f-a48e-2910b0d31255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")\n",
    "  \n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        save_weights_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429806dd-5347-4eb0-8727-4e2c1bba267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189bf9f-bb0d-4b01-a85e-2461c4b97dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the best weights into the model\n",
    "model.load_weights(\"feature_extraction_with_data_augmentation.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf92be-3856-4581-b8ac-067d4262d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33376395-fc0a-4c07-a8da-4dcf60b604bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6c9c0-a6ea-4271-9cc7-359ab424e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd26417-9b12-4e32-be00-e263e1c952e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a53b65-7877-41b7-b50d-088204f0c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989d07e-572d-4d53-a3f7-9c4e7d66c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca9918-ca03-4a15-b093-85f16f414f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"fine_tuning.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "        save_weights_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16788d-90a6-4974-bbb2-7ca3b1feef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4c32-1fb5-4456-b7c0-a0bef2476c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"fine_tuning.keras\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
